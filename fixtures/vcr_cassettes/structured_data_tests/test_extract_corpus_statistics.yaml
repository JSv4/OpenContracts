interactions:
- request:
    body: "{\"messages\":[{\"role\":\"system\",\"content\":\"<BACKGROUND_CONTEXT>\\nYou
      are an expert assistant designed to analyze and answer queries about a collection
      of documents called 'Test Corpus'.\\n\\n**Available Tools:**\\nYou have access
      to comprehensive tools for analyzing documents in this corpus:\\n\\n1. **Document-Specific
      Tools** \u2013 available *per* document via the `ask_document` helper:\\n   -
      Vector search inside that document\\n   - Summary & note access\\n   - Annotation
      manipulation (subject to approval)\\n   - Token length calculations for context
      management\\n2. **Corpus-Level Coordination Tools** \u2013 orchestrate multi-document
      reasoning:\\n   - `list_documents()`\u2003\u2192 returns `[{document_id, title,
      description}]` for discovery\\n   - `ask_document(document_id, question)`\u2003\u2192
      runs a **document agent** and yields a rich object:\\n       \u2022 `answer`\u2003str
      \u2013 the assistant's final answer\\n       \u2022 `sources`\u2003list \u2013
      flattened citation objects (annotation_id, page, rawText \u2026)\\n       \u2022
      `timeline`\u2003list \u2013 detailed reasoning & tool calls from the sub-agent
      run\\n   Use these keys to compile thorough, well-cited corpus-level answers.\\n3.
      **Cross-Document Vector Search** \u2013 semantic search across the entire corpus
      for broad context\\n\\n**Important**: Always check what tools are available
      to you, as additional specialized tools may be provided dynamically beyond the
      core set. The exact tools available will depend on the documents in this corpus.\\n\\n**Guidelines:**\\n-
      Always use the provided tools to gather information before answering\\n- Do
      not rely on prior knowledge about the documents\\n- When appropriate, search
      across multiple documents for comprehensive answers\\n- Cite specific documents
      and sources when presenting information\\n- Prefer using `sources` returned
      by `ask_document` or vector search to justify claims\\n- Present your findings
      in clear, well-structured markdown format, using footnote-style citations\\n</BACKGROUND_CONTEXT>\\n\\nYou
      are a highly-intelligent data extraction system with advanced verification capabilities.\\n\\nEXTRACTION
      METHODOLOGY:\\n1. GATHER: Use available tools (similarity_search, load_document_md_summary,
      etc.) to find ALL relevant information\\n2. EXTRACT: Identify the specific data
      requested in: \\\"Extract basic statistics about a corpus of legal documents
      including Title 1.\\\"\\n3. VERIFY: Before outputting, internally validate your
      extraction by:\\n   - Confirming the requested information ACTUALLY EXISTS in
      the document\\n   - Cross-referencing multiple sources if available\\n   - Checking
      for logical consistency (dates in order, numbers reasonable, etc.)\\n   - Ensuring
      no placeholder or generic values (like \\\"N/A\\\" unless actually in the document)\\n
      \  - Confirming extracted text actually appears in the source material\\n   -
      For lists/collections: searching again with different queries to ensure completeness\\n\\nCRITICAL
      RULES:\\n- If the requested information does not exist or is not applicable
      to this document, return null\\n- If a question doesn't make sense for this
      document type, return null\\n- NEVER invent, guess, or infer data that isn't
      explicitly present\\n- If data is not found after thorough search, return null/empty
      rather than guessing\\n- If multiple conflicting values exist, choose the most
      authoritative/recent\\n- For numeric values, verify they make sense in context\\n-
      For dates, ensure they follow logical chronology and are actually present\\n-
      For names/entities, verify exact spelling from the source\\n- For boolean questions,
      only return true/false if you can definitively answer based on document content\\n\\nYour
      response must be ONLY the extracted data in the format of: a JSON object matching
      the 'CorpusStats' model structure\\n\\nNo explanations, no process description,
      no confidence scores - just the final verified JSON.\\n\\nJSON Schema for your
      response:\\n```json\\n{\\n  \\\"properties\\\": {\\n    \\\"document_count\\\":
      {\\n      \\\"title\\\": \\\"Document Count\\\",\\n      \\\"type\\\": \\\"integer\\\"\\n
      \   },\\n    \\\"total_pages\\\": {\\n      \\\"title\\\": \\\"Total Pages\\\",\\n
      \     \\\"type\\\": \\\"integer\\\"\\n    },\\n    \\\"average_document_length\\\":
      {\\n      \\\"title\\\": \\\"Average Document Length\\\",\\n      \\\"type\\\":
      \\\"number\\\"\\n    },\\n    \\\"most_common_document_type\\\": {\\n      \\\"title\\\":
      \\\"Most Common Document Type\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    }\\n
      \ },\\n  \\\"required\\\": [\\n    \\\"document_count\\\",\\n    \\\"total_pages\\\",\\n
      \   \\\"average_document_length\\\",\\n    \\\"most_common_document_type\\\"\\n
      \ ],\\n  \\\"title\\\": \\\"CorpusStats\\\",\\n  \\\"type\\\": \\\"object\\\"\\n}\\n```\"},{\"role\":\"user\",\"content\":\"Extract
      basic statistics about a corpus of legal documents including Title 1.\"}],\"model\":\"gpt-4o-mini\",\"stream\":false,\"temperature\":0.7,\"tool_choice\":\"required\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"final_result\",\"description\":\"The
      final response which ends this conversation\",\"parameters\":{\"properties\":{\"document_count\":{\"type\":\"integer\"},\"total_pages\":{\"type\":\"integer\"},\"average_document_length\":{\"type\":\"number\"},\"most_common_document_type\":{\"type\":\"string\"}},\"required\":[\"document_count\",\"total_pages\",\"average_document_length\",\"most_common_document_type\"],\"type\":\"object\"}}}]}"
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '5164'
      content-type:
      - application/json
      cookie:
      - __cf_bm=v9Slg21i2yr0blW7WDX1hu7JKBc1EZ_aTLYSmJATqOA-1751734072-1.0.1.1-RSuNwUxbx7LA1Ekz1C5d5zepwxxBjV6y9v59Rg.wdc5AZ0Ptfv52eGr9ywiPhBL2Io5Huzg0XMfWomOHBDuBQCR.yu4hknV9TPgPNg_wp.w;
        _cfuvid=kMKUTBGLMaKftLBwLgoFNITkjQukVlSgpJGCbONDQEU-1751734072392-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '1'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA4xUTU/bQBC9+1es5pwgO4QQcoNyqAQCtVJbqQ1aDeuxs3Q/zO6alkb579Wuie0A
        leqDZc+bN/P2zdjbjDGQJawYiA0GoRs1vXjMby7pW3v7/dfnmz+Xt0vxmPtz9eX8Sn9YwCQy7P0D
        ibBnHQmrG0VBWtPBwhEGilWL05Pi9HhenBUJ0LYkFWl1E6ZzO9XSyOksn82n+em0WL6wN1YK8rBi
        PzLGGNume9RpSvoNK5ZP9hFN3mNNsOqTGANnVYwAei99QBNgMoDCmkAmSjetUiMgWKu4QKWGxt21
        HT0PZqFS3D18Wlz7ubBXi2Kef51txO28+KjbUb+u9HOTBFWtEb1JI7yPr141YwwM6o4rDSruyLcq
        vOIzBujqVpMJUTts11Bakd65sK0J6ziIfMLWEGxAxRusyafgSYriEzmsifcsRaYOmy7jKKVo62Mx
        ra0Z0uK5YtIarqlGxS6cpGoNOziQt8vee74bWe+oaj2qtzNBY2zAaE0ayt0Lsuvnr2zdOHvvX1Gj
        W9JvuCP0ydbxdLO9kCQB2oMFgsZZ3QQe7E9KTc+Wi64qDEs+oCezF7Azto8X+fFy8k5BXlJAmVas
        32qBYkPlwB22G9tS2hGQjQ7/Vs57tTsDpKn/p/wACEFNoJI3jkopDo88pDmKP4F/pfU2J8HgyT1J
        QTxIcnEgJVW4X2Xwzz6Q5pU0NbnGyfR9QtXwxQxnx7gsqIJsl/0FAAD//wMA0DoPuq0EAAA=
    headers:
      CF-RAY:
      - 95a85baa1dbae5b1-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sat, 05 Jul 2025 16:49:52 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '913'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '918'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3998890'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 16ms
      x-request-id:
      - req_c1f6711de188454b4858642d6fa3424b
    status:
      code: 200
      message: OK
version: 1
