interactions:
- request:
    body: '{"messages":[{"role":"system","content":"<BACKGROUND_CONTEXT>\nYou are
      an expert assistant for document analysis and interpretation. Your primary goal
      is to answer questions accurately based on document ''Test Doc'' (ID: 1).\n\nThis
      document is described as:\n`USC Title 1 - Chapter 1`\n\n**Available Tools:**\nYou
      have access to a comprehensive set of tools for document analysis:\n\n1. **Vector
      Search**: A sophisticated semantic search engine that finds text passages similar
      to your queries.\n2. **Document Summary Access**: Tools to load and analyze
      the document''s markdown summary, including:\n   - Loading full or truncated
      summary content\n   - Calculating token lengths for context management\n3. **Notes
      Analysis**: Tools to retrieve and examine notes attached to this document:\n   -
      Listing all notes with metadata\n   - Accessing specific note content\n   -
      Calculating note token lengths\n\n**Important**: Always check what tools are
      available to you, as additional specialized tools may be provided dynamically
      beyond the core set described above. Use the appropriate tools to gather information
      before answering.\n\n**Guidelines:**\n- Prioritize information retrieved directly
      from the document using these tools\n- We intentionally did not give you the
      entire document initially. \n  Try doing some vector search to get more information
      initially and then iteratively \n  identifying which parts of the document to
      review.  \n- Do not rely solely on the summary or your general knowledge\n-
      Use multiple tools when necessary for comprehensive answers\n- Present your
      findings in clear, helpful markdown format\n- Avoid repeating instructions or
      disclaimers in your responses\n</BACKGROUND_CONTEXT>\n\nYou are a highly-intelligent
      data extraction system with advanced verification capabilities.\n\nEXTRACTION
      METHODOLOGY:\n1. GATHER: Use available tools (similarity_search, load_document_md_summary,
      etc.) to find ALL relevant information\n2. EXTRACT: Identify the specific data
      requested in: \"Extract a list of the terms that Section 1 defines as being
      included under the words ''person'' and ''whoever''.\"\n3. VERIFY: Before outputting,
      internally validate your extraction by:\n   - Confirming the requested information
      ACTUALLY EXISTS in the document\n   - Cross-referencing multiple sources if
      available\n   - Checking for logical consistency (dates in order, numbers reasonable,
      etc.)\n   - Ensuring no placeholder or generic values (like \"N/A\" unless actually
      in the document)\n   - Confirming extracted text actually appears in the source
      material\n   - For lists/collections: searching again with different queries
      to ensure completeness\n\nCRITICAL RULES:\n- If the requested information does
      not exist or is not applicable to this document, return null\n- If a question
      doesn''t make sense for this document type, return null\n- NEVER invent, guess,
      or infer data that isn''t explicitly present\n- If data is not found after thorough
      search, return null/empty rather than guessing\n- If multiple conflicting values
      exist, choose the most authoritative/recent\n- For numeric values, verify they
      make sense in context\n- For dates, ensure they follow logical chronology and
      are actually present\n- For names/entities, verify exact spelling from the source\n-
      For boolean questions, only return true/false if you can definitively answer
      based on document content\n\nYour response must be ONLY the extracted data in
      the format of: a JSON array of str values\n\nNo explanations, no process description,
      no confidence scores - just the final verified JSON.\n\nJSON Schema for your
      response:\n```json\n{\n  \"items\": {\n    \"type\": \"string\"\n  },\n  \"type\":
      \"array\"\n}\n```"},{"role":"user","content":"Extract a list of the terms that
      Section 1 defines as being included under the words ''person'' and ''whoever''."}],"model":"gpt-4o-mini","stream":false,"temperature":0.7,"tool_choice":"required","tools":[{"type":"function","function":{"name":"final_result","description":"The
      final response which ends this conversation","parameters":{"additionalProperties":false,"properties":{"response":{"items":{"type":"string"},"type":"array"}},"required":["response"],"type":"object"},"strict":true}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4214'
      content-type:
      - application/json
      cookie:
      - __cf_bm=v9Slg21i2yr0blW7WDX1hu7JKBc1EZ_aTLYSmJATqOA-1751734072-1.0.1.1-RSuNwUxbx7LA1Ekz1C5d5zepwxxBjV6y9v59Rg.wdc5AZ0Ptfv52eGr9ywiPhBL2Io5Huzg0XMfWomOHBDuBQCR.yu4hknV9TPgPNg_wp.w;
        _cfuvid=kMKUTBGLMaKftLBwLgoFNITkjQukVlSgpJGCbONDQEU-1751734072392-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '1'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFPBjpswEL3zFdacQwUkDVlu3Uo9bdtTV2p3IzQxA3FrbMc2adIo/14B
        CZDdrVQOyJrnN/PmzfgUMAaigIwB36LntZHh/S76cjhW9wtOnwx//LqLNkuSxecDPux+wKxl6M1P
        4v7Kesd1bSR5oVUPc0voqc0ap+/jdL5I5mkH1Log2dIq48OFDmuhRJhEySKM0jBeXdhbLTg5yNhT
        wBhjp+7f6lQFHSBj0ewaqck5rAiy4RJjYLVsI4DOCedReZiNINfKk2qlq0bKCeC1ljlHKcfC/Xea
        nEezUMpciyR6iDn/s/ffzbflh0e+97/rw8dJvT710XSCykbxwaQJPsSzF8UYA4V1zxUKZW7JNdK/
        4DMGaKumJuVb7XB6BkvOaOXoGbKn9Rlurp+Dt87riRWWysahfO0RKqU9tlI7k9YX5DzMQ+rKWL1x
        L6iteuG2uSV0XZtTt4OrkE4CNDcDBWN1bXzu9S/qiqZ3aZ8VxqUb0Xh+Ab32KMf4Kr7szG2+vCCP
        opv4sGQc+ZaKkTouGzaF0BMgmPT+Ws1bufv+har+J/0IcE7GU5EbS4Xgtx2P1yy1b/Jf1waXO8Hg
        yO4Fp9wLsu08Cirxulngjs5TnZdCVWSNFd1zgdLkywSTOa5iKiE4B38BAAD//wMA44wk6jwEAAA=
    headers:
      CF-RAY:
      - 95a85cc4eec7f06c-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sat, 05 Jul 2025 16:50:37 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '486'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '540'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3999075'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 13ms
      x-request-id:
      - req_22966468dad9ec0c9381cb006ee33f57
    status:
      code: 200
      message: OK
version: 1
