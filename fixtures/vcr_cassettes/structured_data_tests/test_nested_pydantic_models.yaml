interactions:
- request:
    body: '{"messages":[{"role":"system","content":"<BACKGROUND_CONTEXT>\nYou are
      an expert assistant for document analysis and interpretation. Your primary goal
      is to answer questions accurately based on document ''Test Doc'' (ID: 1).\n\nThis
      document is described as:\n`USC Title 1 - Chapter 1`\n\n**Available Tools:**\nYou
      have access to a comprehensive set of tools for document analysis:\n\n1. **Vector
      Search**: A sophisticated semantic search engine that finds text passages similar
      to your queries.\n2. **Document Summary Access**: Tools to load and analyze
      the document''s markdown summary, including:\n   - Loading full or truncated
      summary content\n   - Calculating token lengths for context management\n3. **Notes
      Analysis**: Tools to retrieve and examine notes attached to this document:\n   -
      Listing all notes with metadata\n   - Accessing specific note content\n   -
      Calculating note token lengths\n\n**Important**: Always check what tools are
      available to you, as additional specialized tools may be provided dynamically
      beyond the core set described above. Use the appropriate tools to gather information
      before answering.\n\n**Guidelines:**\n- Prioritize information retrieved directly
      from the document using these tools\n- We intentionally did not give you the
      entire document initially. \n  Try doing some vector search to get more information
      initially and then iteratively \n  identifying which parts of the document to
      review.  \n- Do not rely solely on the summary or your general knowledge\n-
      Use multiple tools when necessary for comprehensive answers\n- Present your
      findings in clear, helpful markdown format\n- Avoid repeating instructions or
      disclaimers in your responses\n</BACKGROUND_CONTEXT>\n\nYou are a highly-intelligent
      data extraction system with NO PRIOR KNOWLEDGE about any documents. You must
      ONLY use information obtained through the provided tools.\n\nAVAILABLE TOOLS
      FOR DOCUMENT ANALYSIS:\n- similarity_search: Semantic vector search to find
      relevant passages based on meaning\n- load_document_md_summary: Access markdown
      summary of the document (if available)\n- load_document_txt_extract: Load plain
      text extract of document (full or partial)\n- get_document_notes: Retrieve human-created
      notes attached to this document\n- search_document_notes: Search through notes
      for specific keywords\n- get_document_summary: Get the latest human-prepared
      summary content\n- add_exact_string_annotations: Find exact string matches in
      the document\n- Other document-specific tools may be available\n\nCRITICAL OPERATING
      PRINCIPLES:\n1. You have ZERO knowledge about this document except what you
      discover through tools\n2. NEVER assume, infer, or use any information not explicitly
      found via tool calls\n3. If you cannot find requested information after thorough
      search, return null\n4. Your answers must be 100% traceable to specific tool
      results\n\nEXTRACTION METHODOLOGY:\n\nPHASE 1 - COMPREHENSIVE SEARCH:\n1. Analyze
      the extraction request: \"Extract company information from this document\"\n2.
      Plan multiple search strategies using different tools and query variations\n3.
      Execute searches systematically:\n   - Try semantic search with various phrasings\n   -
      Load document summary if relevant\n   - Search notes if they might contain the
      information\n   - Access document text for detailed inspection\n4. Collect ALL
      potentially relevant information\n\nPHASE 2 - INITIAL EXTRACTION:\n1. Review
      all gathered information\n2. Extract ONLY data that directly answers the request\n3.
      For each piece of extracted data, note its source (which tool, what result)\n4.
      If information is ambiguous or conflicting, prefer the most authoritative source\n5.
      If required information is not found, prepare to return null for those fields\n\nPHASE
      3 - BACKWARD VERIFICATION (CRITICAL):\n1. Take your proposed answer and work
      backwards\n2. For EACH data point in your answer:\n   - Can you cite the EXACT
      tool call and result that provided this information?\n   - Does the source material
      actually say what you claim it says?\n   - Is this a direct quote/fact or are
      you interpreting/inferring?\n3. If ANY data point fails verification:\n   -
      Remove unverifiable data\n   - Search again with more targeted queries\n   -
      If still not found, that field should be null\n\nPHASE 4 - ITERATION IF NEEDED:\nIf
      backward verification revealed gaps or errors:\n1. Identify what specific information
      is missing or wrong\n2. Formulate new, more targeted search queries\n3. Return
      to PHASE 1 with these specific queries\n4. Repeat until either:\n   - All data
      is verified with clear sources, OR\n   - You''ve exhausted search options and
      must return null\n\nVERIFICATION RULES:\n- Dates must be explicitly stated in
      the source material (not inferred from context)\n- Numbers must be exact matches
      from the document (not calculated or estimated)\n- Names/entities must appear
      verbatim (not paraphrased or corrected)\n- Boolean values require explicit supporting
      statements\n- Lists must be complete based on the source (not \"including but
      not limited to\")\n- For relationships, both entities and the relationship must
      be explicitly stated\n\nOUTPUT RULES:\n- Return ONLY the extracted data in this
      exact format: \n\na JSON object matching the ''Company'' model with this schema:\n{\n  \"$defs\":
      {\n    \"Address\": {\n      \"properties\": {\n        \"street\": {\n          \"title\":
      \"Street\",\n          \"type\": \"string\"\n        },\n        \"city\": {\n          \"title\":
      \"City\",\n          \"type\": \"string\"\n        },\n        \"state\": {\n          \"title\":
      \"State\",\n          \"type\": \"string\"\n        },\n        \"zip_code\":
      {\n          \"title\": \"Zip Code\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\":
      [\n        \"street\",\n        \"city\",\n        \"state\",\n        \"zip_code\"\n      ],\n      \"title\":
      \"Address\",\n      \"type\": \"object\"\n    },\n    \"Company\": {\n      \"properties\":
      {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\":
      \"string\"\n        },\n        \"address\": {\n          \"$ref\": \"#/$defs/Address\"\n        },\n        \"subsidiaries\":
      {\n          \"default\": [],\n          \"items\": {\n            \"$ref\":
      \"#/$defs/Company\"\n          },\n          \"title\": \"Subsidiaries\",\n          \"type\":
      \"array\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"address\"\n      ],\n      \"title\":
      \"Company\",\n      \"type\": \"object\"\n    }\n  },\n  \"$ref\": \"#/$defs/Company\"\n}\n\n-
      No explanations, confidence scores, or meta-commentary\n- Use null/empty for
      missing data rather than placeholders\n- The entire response must be valid string
      representation of desired answer convertible to the target type\n\nUser has
      provided the following additional context (if blank, nothing provided):\n\n"},{"role":"user","content":"Extract
      company information from this document"}],"model":"gpt-4o-mini","stream":false,"temperature":0.7,"tool_choice":"required","tools":[{"type":"function","function":{"name":"final_result","description":"The
      final response which ends this conversation","parameters":{"$defs":{"Address":{"properties":{"street":{"type":"string"},"city":{"type":"string"},"state":{"type":"string"},"zip_code":{"type":"string"}},"required":["street","city","state","zip_code"],"type":"object"},"Company":{"properties":{"name":{"type":"string"},"address":{"$ref":"#/$defs/Address"},"subsidiaries":{"items":{"$ref":"#"},"type":"array"}},"required":["name","address"],"type":"object"}},"properties":{"name":{"type":"string"},"address":{"$ref":"#/$defs/Address"},"subsidiaries":{"items":{"$ref":"#"},"type":"array"}},"required":["name","address"],"type":"object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '7756'
      content-type:
      - application/json
      cookie:
      - __cf_bm=4_gmVURDuZKY2geW67mrcJmHfSge7MQ6SQYwvcO3Rcw-1751760736-1.0.1.1-OHBOavi5r3Bj3TshtVcWhIDYemLMOc.LZZ.Zh8OP7xw7dvNPNBJfUURLqOsW68hVAMUCQMTAsp1NZRACyCHj7Ptlaw9kkWMvvPLkqb7MCRg;
        _cfuvid=nJAMzKDSO8HRLgzCw8QUEzEHfaRUzTBvizMw8371j24-1751760736988-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '1'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFPLbtswELzrK4g9x4Xl+KlbGhSoizSHoC8kDgSaXMtsKZIhV0UTw/9e
        kH5ITlygOgjSzs7scHe5yRgDJaFgINacRO107/3T5GYu8o+3da3m32e3n3L7YkZ3Js/r2TVcRIZd
        /kRBB9Y7YWunkZQ1O1h45IRRNZ+M8sm4P5v2E1BbiTrSKke9oe3VyqjeoD8Y9vqTXj7ds9dWCQxQ
        sIeMMcY26R19Gol/oGBJK0VqDIFXCMUxiTHwVscI8BBUIG4ILlpQWENoonXTaN0ByFpdCq51W3j3
        bDrfbbO41uUdjqsP3+7d0+xmfPP56seXr1fza7m+79TbST+7ZGjVGHFsUgc/xotXxRgDw+sdVxmu
        S4+h0fSKzxhwXzU1GoreYbNIrAUU6YgL4FJ6DGEBxWYBgTwitaBQ9Nz+BeLUYb4oVworD5FtzGiW
        QUnFvcKo+PC4hRM32+zc92On0x5XTeD67Qi4MZZ47ESaweMe2R7HrW3lvF2GV9TYHBXWpUceUhe7
        w8wORpIFaE72BZy3taOS7C9MRfPhaLaThXapW/hyugfJEtdd2mxycUaxlEhcpZU6brHgYo2y5bbb
        zBupbAfIOqd/a+ec9q4DylT/I98CQqAjlKXzKJU4PXKb5jFe+n+lHfucDENA/1sJLEmhjxORuOKH
        1YXwHAjrcqVMhd55le4jrFw5HvDBJZ/muIJsm/0FAAD//wMA3CP3Xp0EAAA=
    headers:
      CF-RAY:
      - 95aae9b10e261376-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 06 Jul 2025 00:16:21 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '676'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '679'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3998347'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 24ms
      x-request-id:
      - req_a660312372612b906b6491057916ae7d
    status:
      code: 200
      message: OK
- request:
    body: '{"messages":[{"role":"system","content":"<BACKGROUND_CONTEXT>\nYou are
      an expert assistant for document analysis and interpretation. Your primary goal
      is to answer questions accurately based on document ''Test Doc'' (ID: 1).\n\nThis
      document is described as:\n`USC Title 1 - Chapter 1`\n\n**Available Tools:**\nYou
      have access to a comprehensive set of tools for document analysis:\n\n1. **Vector
      Search**: A sophisticated semantic search engine that finds text passages similar
      to your queries.\n2. **Document Summary Access**: Tools to load and analyze
      the document''s markdown summary, including:\n   - Loading full or truncated
      summary content\n   - Calculating token lengths for context management\n3. **Notes
      Analysis**: Tools to retrieve and examine notes attached to this document:\n   -
      Listing all notes with metadata\n   - Accessing specific note content\n   -
      Calculating note token lengths\n\n**Important**: Always check what tools are
      available to you, as additional specialized tools may be provided dynamically
      beyond the core set described above. Use the appropriate tools to gather information
      before answering.\n\n**Guidelines:**\n- Prioritize information retrieved directly
      from the document using these tools\n- We intentionally did not give you the
      entire document initially. \n  Try doing some vector search to get more information
      initially and then iteratively \n  identifying which parts of the document to
      review.  \n- Do not rely solely on the summary or your general knowledge\n-
      Use multiple tools when necessary for comprehensive answers\n- Present your
      findings in clear, helpful markdown format\n- Avoid repeating instructions or
      disclaimers in your responses\n</BACKGROUND_CONTEXT>\n\nYou are a highly-intelligent
      data extraction system with NO PRIOR KNOWLEDGE about any documents. You must
      ONLY use information obtained through the provided tools.\n\nAVAILABLE TOOLS
      FOR DOCUMENT ANALYSIS:\n- similarity_search: Semantic vector search to find
      relevant passages based on meaning\n- load_document_md_summary: Access markdown
      summary of the document (if available)\n- load_document_txt_extract: Load plain
      text extract of document (full or partial)\n- get_document_notes: Retrieve human-created
      notes attached to this document\n- search_document_notes: Search through notes
      for specific keywords\n- get_document_summary: Get the latest human-prepared
      summary content\n- add_exact_string_annotations: Find exact string matches in
      the document\n- Other document-specific tools may be available\n\nCRITICAL OPERATING
      PRINCIPLES:\n1. You have ZERO knowledge about this document except what you
      discover through tools\n2. NEVER assume, infer, or use any information not explicitly
      found via tool calls\n3. If you cannot find requested information after thorough
      search, return null\n4. Your answers must be 100% traceable to specific tool
      results\n\nEXTRACTION METHODOLOGY:\n\nPHASE 1 - COMPREHENSIVE SEARCH:\n1. Analyze
      the extraction request: \"Extract company information from this document\"\n2.
      Plan multiple search strategies using different tools and query variations\n3.
      Execute searches systematically:\n   - Try semantic search with various phrasings\n   -
      Load document summary if relevant\n   - Search notes if they might contain the
      information\n   - Access document text for detailed inspection\n4. Collect ALL
      potentially relevant information\n\nPHASE 2 - INITIAL EXTRACTION:\n1. Review
      all gathered information\n2. Extract ONLY data that directly answers the request\n3.
      For each piece of extracted data, note its source (which tool, what result)\n4.
      If information is ambiguous or conflicting, prefer the most authoritative source\n5.
      If required information is not found, prepare to return null for those fields\n\nPHASE
      3 - BACKWARD VERIFICATION (CRITICAL):\n1. Take your proposed answer and work
      backwards\n2. For EACH data point in your answer:\n   - Can you cite the EXACT
      tool call and result that provided this information?\n   - Does the source material
      actually say what you claim it says?\n   - Is this a direct quote/fact or are
      you interpreting/inferring?\n3. If ANY data point fails verification:\n   -
      Remove unverifiable data\n   - Search again with more targeted queries\n   -
      If still not found, that field should be null\n\nPHASE 4 - ITERATION IF NEEDED:\nIf
      backward verification revealed gaps or errors:\n1. Identify what specific information
      is missing or wrong\n2. Formulate new, more targeted search queries\n3. Return
      to PHASE 1 with these specific queries\n4. Repeat until either:\n   - All data
      is verified with clear sources, OR\n   - You''ve exhausted search options and
      must return null\n\nVERIFICATION RULES:\n- Dates must be explicitly stated in
      the source material (not inferred from context)\n- Numbers must be exact matches
      from the document (not calculated or estimated)\n- Names/entities must appear
      verbatim (not paraphrased or corrected)\n- Boolean values require explicit supporting
      statements\n- Lists must be complete based on the source (not \"including but
      not limited to\")\n- For relationships, both entities and the relationship must
      be explicitly stated\n\nOUTPUT RULES:\n- Return ONLY the extracted data in this
      exact format: \n\na JSON object matching the ''Company'' model with this schema:\n{\n  \"$defs\":
      {\n    \"Address\": {\n      \"properties\": {\n        \"street\": {\n          \"title\":
      \"Street\",\n          \"type\": \"string\"\n        },\n        \"city\": {\n          \"title\":
      \"City\",\n          \"type\": \"string\"\n        },\n        \"state\": {\n          \"title\":
      \"State\",\n          \"type\": \"string\"\n        },\n        \"zip_code\":
      {\n          \"title\": \"Zip Code\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\":
      [\n        \"street\",\n        \"city\",\n        \"state\",\n        \"zip_code\"\n      ],\n      \"title\":
      \"Address\",\n      \"type\": \"object\"\n    },\n    \"Company\": {\n      \"properties\":
      {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\":
      \"string\"\n        },\n        \"address\": {\n          \"$ref\": \"#/$defs/Address\"\n        },\n        \"subsidiaries\":
      {\n          \"default\": [],\n          \"items\": {\n            \"$ref\":
      \"#/$defs/Company\"\n          },\n          \"title\": \"Subsidiaries\",\n          \"type\":
      \"array\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"address\"\n      ],\n      \"title\":
      \"Company\",\n      \"type\": \"object\"\n    }\n  },\n  \"$ref\": \"#/$defs/Company\"\n}\n\n-
      No explanations, confidence scores, or meta-commentary\n- Use null/empty for
      missing data rather than placeholders\n- The entire response must be valid string
      representation of desired answer convertible to the target type\n\nUser has
      provided the following additional context (if blank, nothing provided):\n\n"},{"role":"user","content":"Extract
      company information from this document"},{"role":"assistant","tool_calls":[{"id":"call_Re6gEVZpq9L6LMAXTUAICdhZ","type":"function","function":{"name":"final_result","arguments":"{\"name\":null,\"address\":{\"street\":null,\"city\":null,\"state\":null,\"zip_code\":null},\"subsidiaries\":[]}"}}]},{"role":"tool","tool_call_id":"call_Re6gEVZpq9L6LMAXTUAICdhZ","content":"5
      validation errors: [\n  {\n    \"type\": \"string_type\",\n    \"loc\": [\n      \"name\"\n    ],\n    \"msg\":
      \"Input should be a valid string\",\n    \"input\": null\n  },\n  {\n    \"type\":
      \"string_type\",\n    \"loc\": [\n      \"address\",\n      \"street\"\n    ],\n    \"msg\":
      \"Input should be a valid string\",\n    \"input\": null\n  },\n  {\n    \"type\":
      \"string_type\",\n    \"loc\": [\n      \"address\",\n      \"city\"\n    ],\n    \"msg\":
      \"Input should be a valid string\",\n    \"input\": null\n  },\n  {\n    \"type\":
      \"string_type\",\n    \"loc\": [\n      \"address\",\n      \"state\"\n    ],\n    \"msg\":
      \"Input should be a valid string\",\n    \"input\": null\n  },\n  {\n    \"type\":
      \"string_type\",\n    \"loc\": [\n      \"address\",\n      \"zip_code\"\n    ],\n    \"msg\":
      \"Input should be a valid string\",\n    \"input\": null\n  }\n]\n\nFix the
      errors and try again."}],"model":"gpt-4o-mini","stream":false,"temperature":0.7,"tool_choice":"required","tools":[{"type":"function","function":{"name":"final_result","description":"The
      final response which ends this conversation","parameters":{"$defs":{"Address":{"properties":{"street":{"type":"string"},"city":{"type":"string"},"state":{"type":"string"},"zip_code":{"type":"string"}},"required":["street","city","state","zip_code"],"type":"object"},"Company":{"properties":{"name":{"type":"string"},"address":{"$ref":"#/$defs/Address"},"subsidiaries":{"items":{"$ref":"#"},"type":"array"}},"required":["name","address"],"type":"object"}},"properties":{"name":{"type":"string"},"address":{"$ref":"#/$defs/Address"},"subsidiaries":{"items":{"$ref":"#"},"type":"array"}},"required":["name","address"],"type":"object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '9001'
      content-type:
      - application/json
      cookie:
      - __cf_bm=4_gmVURDuZKY2geW67mrcJmHfSge7MQ6SQYwvcO3Rcw-1751760736-1.0.1.1-OHBOavi5r3Bj3TshtVcWhIDYemLMOc.LZZ.Zh8OP7xw7dvNPNBJfUURLqOsW68hVAMUCQMTAsp1NZRACyCHj7Ptlaw9kkWMvvPLkqb7MCRg;
        _cfuvid=nJAMzKDSO8HRLgzCw8QUEzEHfaRUzTBvizMw8371j24-1751760736988-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RU227bMAx991cIfE4G57Im9dsKdBvWYhiKXVDUhcFItKNOljRJLpYF+fdBTmI7
        aesHQ+DhIY8OaW8TxkAKyBjwNQZeWzW++rO4/VLf/2jK52talfcVpfLr3eUnwttfHkaRYVZPxMOR
        9Y6b2ioK0ug9zB1hoFh1sng/WVykl8tJC9RGkIq0yobx3IxrqeV4mk7n43QxniwP7LWRnDxk7CFh
        jLFt+446taC/kLF0dIzU5D1WBFmXxBg4o2IE0HvpA+oAox7kRgfSUbpulBoAwRhVcFSqb7x/toNz
        bxYqVdR31c/r7x+v1rW7WfOnbx9umtlnaeyg3770xraCykbzzqQB3sWzs2aMgcZ6z5UaVeHINyqc
        8RkDdFVTkw5RO2zzlpVDlkO8ZA6jHFAIR97nkG1z8MERhdMELsPmNOIDhrMq/6QtuBHD6C5mNisv
        hUQnKXZ4eNzBicJd8tr5ceC+o7LxqF6OBbU2AaM77VweD8iuWwFlKuvMyp9Ro2HSrwtH6FtnhwNO
        jkJaCdCc7BBYZ2obimB+U9t0spgfNg76Re/h2eUBDCagGtIWR+SkYiEooGzXrNtsjnxNYsCdp8vu
        JtgIaXosTQYGvFT0Wvm9CVJXgypvlu8BzskGEoV1JCQ/vXWf5ij+C95K66xuBYMn9yw5FUGSi0MR
        VOJxo8FvfKC6KKWuyFkn288USltcTHE6w+WESkh2yX8AAAD//wMAEBJM17QEAAA=
    headers:
      CF-RAY:
      - 95aae9b5bb881376-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 06 Jul 2025 00:16:22 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '951'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '955'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3998147'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 27ms
      x-request-id:
      - req_5601baf6347232068f862dc07cabaf9f
    status:
      code: 200
      message: OK
version: 1
