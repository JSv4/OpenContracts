interactions:
- request:
    body: '{"messages":[{"role":"system","content":"<BACKGROUND_CONTEXT>\nYou are
      an expert assistant for document analysis and interpretation. Your primary goal
      is to answer questions accurately based on document ''Test Doc'' (ID: 1).\n\nThis
      document is described as:\n`USC Title 1 - Chapter 1`\n\n**Available Tools:**\nYou
      have access to a comprehensive set of tools for document analysis:\n\n1. **Vector
      Search**: A sophisticated semantic search engine that finds text passages similar
      to your queries.\n2. **Document Summary Access**: Tools to load and analyze
      the document''s markdown summary, including:\n   - Loading full or truncated
      summary content\n   - Calculating token lengths for context management\n3. **Notes
      Analysis**: Tools to retrieve and examine notes attached to this document:\n   -
      Listing all notes with metadata\n   - Accessing specific note content\n   -
      Calculating note token lengths\n\n**Important**: Always check what tools are
      available to you, as additional specialized tools may be provided dynamically
      beyond the core set described above. Use the appropriate tools to gather information
      before answering.\n\n**Guidelines:**\n- Prioritize information retrieved directly
      from the document using these tools\n- We intentionally did not give you the
      entire document initially. \n  Try doing some vector search to get more information
      initially and then iteratively \n  identifying which parts of the document to
      review.  \n- Do not rely solely on the summary or your general knowledge\n-
      Use multiple tools when necessary for comprehensive answers\n- Present your
      findings in clear, helpful markdown format\n- Avoid repeating instructions or
      disclaimers in your responses\n</BACKGROUND_CONTEXT>\n\nYou are a highly-intelligent
      data extraction system with NO PRIOR KNOWLEDGE about any documents. You must
      ONLY use information obtained through the provided tools.\n\nAVAILABLE TOOLS
      FOR DOCUMENT ANALYSIS:\n- similarity_search: Semantic vector search to find
      relevant passages based on meaning\n- load_document_md_summary: Access markdown
      summary of the document (if available)\n- load_document_txt_extract: Load plain
      text extract of document (full or partial)\n- get_document_notes: Retrieve human-created
      notes attached to this document\n- search_document_notes: Search through notes
      for specific keywords\n- get_document_summary: Get the latest human-prepared
      summary content\n- add_exact_string_annotations: Find exact string matches in
      the document\n- Other document-specific tools may be available\n\nCRITICAL OPERATING
      PRINCIPLES:\n1. You have ZERO knowledge about this document except what you
      discover through tools\n2. NEVER assume, infer, or use any information not explicitly
      found via tool calls\n3. If you cannot find requested information after thorough
      search, return null\n4. Your answers must be 100% traceable to specific tool
      results\n\nEXTRACTION METHODOLOGY:\n\nPHASE 1 - COMPREHENSIVE SEARCH:\n1. Analyze
      the extraction request: \"Extract some data that definitely won''t match this
      complex structure\"\n2. Plan multiple search strategies using different tools
      and query variations\n3. Execute searches systematically:\n   - Try semantic
      search with various phrasings\n   - Load document summary if relevant\n   -
      Search notes if they might contain the information\n   - Access document text
      for detailed inspection\n4. Collect ALL potentially relevant information\n\nPHASE
      2 - INITIAL EXTRACTION:\n1. Review all gathered information\n2. Extract ONLY
      data that directly answers the request\n3. For each piece of extracted data,
      note its source (which tool, what result)\n4. If information is ambiguous or
      conflicting, prefer the most authoritative source\n5. If required information
      is not found, prepare to return null for those fields\n\nPHASE 3 - BACKWARD
      VERIFICATION (CRITICAL):\n1. Take your proposed answer and work backwards\n2.
      For EACH data point in your answer:\n   - Can you cite the EXACT tool call and
      result that provided this information?\n   - Does the source material actually
      say what you claim it says?\n   - Is this a direct quote/fact or are you interpreting/inferring?\n3.
      If ANY data point fails verification:\n   - Remove unverifiable data\n   - Search
      again with more targeted queries\n   - If still not found, that field should
      be null\n\nPHASE 4 - ITERATION IF NEEDED:\nIf backward verification revealed
      gaps or errors:\n1. Identify what specific information is missing or wrong\n2.
      Formulate new, more targeted search queries\n3. Return to PHASE 1 with these
      specific queries\n4. Repeat until either:\n   - All data is verified with clear
      sources, OR\n   - You''ve exhausted search options and must return null\n\nVERIFICATION
      RULES:\n- Dates must be explicitly stated in the source material (not inferred
      from context)\n- Numbers must be exact matches from the document (not calculated
      or estimated)\n- Names/entities must appear verbatim (not paraphrased or corrected)\n-
      Boolean values require explicit supporting statements\n- Lists must be complete
      based on the source (not \"including but not limited to\")\n- For relationships,
      both entities and the relationship must be explicitly stated\n\nOUTPUT RULES:\n-
      Return ONLY the extracted data in this exact format: \n\na JSON object matching
      the ''ComplexModel'' model with this schema:\n{\n  \"properties\": {\n    \"nested_data\":
      {\n      \"additionalProperties\": {\n        \"items\": {\n          \"additionalProperties\":
      {\n            \"type\": \"number\"\n          },\n          \"type\": \"object\"\n        },\n        \"type\":
      \"array\"\n      },\n      \"title\": \"Nested Data\",\n      \"type\": \"object\"\n    }\n  },\n  \"required\":
      [\n    \"nested_data\"\n  ],\n  \"title\": \"ComplexModel\",\n  \"type\": \"object\"\n}\n\n-
      No explanations, confidence scores, or meta-commentary\n- Use null/empty for
      missing data rather than placeholders\n- The entire response must be valid string
      representation of desired answer convertible to the target type\n\nUser has
      provided the following additional context (if blank, nothing provided):\n\n"},{"role":"user","content":"Extract
      some data that definitely won''t match this complex structure"}],"model":"gpt-4o-mini","stream":false,"temperature":2.0,"tool_choice":"required","tools":[{"type":"function","function":{"name":"final_result","description":"The
      final response which ends this conversation","parameters":{"properties":{"nested_data":{"additionalProperties":{"items":{"additionalProperties":{"type":"number"},"type":"object"},"type":"array"},"type":"object"}},"required":["nested_data"],"type":"object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '6599'
      content-type:
      - application/json
      cookie:
      - __cf_bm=4_gmVURDuZKY2geW67mrcJmHfSge7MQ6SQYwvcO3Rcw-1751760736-1.0.1.1-OHBOavi5r3Bj3TshtVcWhIDYemLMOc.LZZ.Zh8OP7xw7dvNPNBJfUURLqOsW68hVAMUCQMTAsp1NZRACyCHj7Ptlaw9kkWMvvPLkqb7MCRg;
        _cfuvid=nJAMzKDSO8HRLgzCw8QUEzEHfaRUzTBvizMw8371j24-1751760736988-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '1'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFPBjpswEL3zFZbPoQpsSCi3tpeoVdWuqlatqhWamAG8MbZjm3S3Uf59
        ZUiAZFOpHJA1z2/mzZvxISCE8oJmhLIaHGu0CN/vVp9/7r49zj9tbV0sF+n+fv/x+9vqw/aXc3Tm
        GWrziMydWW+YarRAx5XsYWYQHPqs0SqJVstonqw6oFEFCk+rtAsXKmy45GE8jxfhfBVG6YldK87Q
        0oz8Dggh5ND9vU5Z4BPNyHx2jjRoLVRIs+ESIdQo4SMUrOXWgew1n0CmpEPppctWiAnglBI5AyHG
        wv13mJxHs0CI/O/X+6eNLH+s07WNYf2nMbt3mERfJvX61M+6E1S2kg0mTfAhnl0VI4RKaHoulyBy
        g7YV7opPCAVTtQ1K57XTw5Fe4Mfg1vlh0rvBsrUgXpsCUioHXlvnysMJOQ4DEKrSRm3sFdXL5bbO
        DYLt+praG5yFdBJoezFBqo1qtMud2mJXNIqTpE9LxzUb4Tg9gU45EFNaeje7kTEv0AHvhjzsFQNW
        YzFyx/2CtuBqAgST7l/LuZW7d4DL6n/SjwBjqB0WuTZYcHbZ8njNoH+G/7o2+NwJphbNnjPMHUfj
        J1JgCedlovbZOmzykssKjTa8eyG01PkyhvgO0ghLGhyDFwAAAP//AwAHpqXeLwQAAA==
    headers:
      CF-RAY:
      - 95aaeb91bc84e7db-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 06 Jul 2025 00:17:38 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '625'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '630'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3998513'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 22ms
      x-request-id:
      - req_bb6e76cae896b0bfed7e219120642cb9
    status:
      code: 200
      message: OK
- request:
    body: '{"messages":[{"role":"system","content":"<BACKGROUND_CONTEXT>\nYou are
      an expert assistant for document analysis and interpretation. Your primary goal
      is to answer questions accurately based on document ''Test Doc'' (ID: 1).\n\nThis
      document is described as:\n`USC Title 1 - Chapter 1`\n\n**Available Tools:**\nYou
      have access to a comprehensive set of tools for document analysis:\n\n1. **Vector
      Search**: A sophisticated semantic search engine that finds text passages similar
      to your queries.\n2. **Document Summary Access**: Tools to load and analyze
      the document''s markdown summary, including:\n   - Loading full or truncated
      summary content\n   - Calculating token lengths for context management\n3. **Notes
      Analysis**: Tools to retrieve and examine notes attached to this document:\n   -
      Listing all notes with metadata\n   - Accessing specific note content\n   -
      Calculating note token lengths\n\n**Important**: Always check what tools are
      available to you, as additional specialized tools may be provided dynamically
      beyond the core set described above. Use the appropriate tools to gather information
      before answering.\n\n**Guidelines:**\n- Prioritize information retrieved directly
      from the document using these tools\n- We intentionally did not give you the
      entire document initially. \n  Try doing some vector search to get more information
      initially and then iteratively \n  identifying which parts of the document to
      review.  \n- Do not rely solely on the summary or your general knowledge\n-
      Use multiple tools when necessary for comprehensive answers\n- Present your
      findings in clear, helpful markdown format\n- Avoid repeating instructions or
      disclaimers in your responses\n</BACKGROUND_CONTEXT>\n\nYou are a highly-intelligent
      data extraction system with NO PRIOR KNOWLEDGE about any documents. You must
      ONLY use information obtained through the provided tools.\n\nAVAILABLE TOOLS
      FOR DOCUMENT ANALYSIS:\n- similarity_search: Semantic vector search to find
      relevant passages based on meaning\n- load_document_md_summary: Access markdown
      summary of the document (if available)\n- load_document_txt_extract: Load plain
      text extract of document (full or partial)\n- get_document_notes: Retrieve human-created
      notes attached to this document\n- search_document_notes: Search through notes
      for specific keywords\n- get_document_summary: Get the latest human-prepared
      summary content\n- add_exact_string_annotations: Find exact string matches in
      the document\n- Other document-specific tools may be available\n\nCRITICAL OPERATING
      PRINCIPLES:\n1. You have ZERO knowledge about this document except what you
      discover through tools\n2. NEVER assume, infer, or use any information not explicitly
      found via tool calls\n3. If you cannot find requested information after thorough
      search, return null\n4. Your answers must be 100% traceable to specific tool
      results\n\nEXTRACTION METHODOLOGY:\n\nPHASE 1 - COMPREHENSIVE SEARCH:\n1. Analyze
      the extraction request: \"Extract some data that definitely won''t match this
      complex structure\"\n2. Plan multiple search strategies using different tools
      and query variations\n3. Execute searches systematically:\n   - Try semantic
      search with various phrasings\n   - Load document summary if relevant\n   -
      Search notes if they might contain the information\n   - Access document text
      for detailed inspection\n4. Collect ALL potentially relevant information\n\nPHASE
      2 - INITIAL EXTRACTION:\n1. Review all gathered information\n2. Extract ONLY
      data that directly answers the request\n3. For each piece of extracted data,
      note its source (which tool, what result)\n4. If information is ambiguous or
      conflicting, prefer the most authoritative source\n5. If required information
      is not found, prepare to return null for those fields\n\nPHASE 3 - BACKWARD
      VERIFICATION (CRITICAL):\n1. Take your proposed answer and work backwards\n2.
      For EACH data point in your answer:\n   - Can you cite the EXACT tool call and
      result that provided this information?\n   - Does the source material actually
      say what you claim it says?\n   - Is this a direct quote/fact or are you interpreting/inferring?\n3.
      If ANY data point fails verification:\n   - Remove unverifiable data\n   - Search
      again with more targeted queries\n   - If still not found, that field should
      be null\n\nPHASE 4 - ITERATION IF NEEDED:\nIf backward verification revealed
      gaps or errors:\n1. Identify what specific information is missing or wrong\n2.
      Formulate new, more targeted search queries\n3. Return to PHASE 1 with these
      specific queries\n4. Repeat until either:\n   - All data is verified with clear
      sources, OR\n   - You''ve exhausted search options and must return null\n\nVERIFICATION
      RULES:\n- Dates must be explicitly stated in the source material (not inferred
      from context)\n- Numbers must be exact matches from the document (not calculated
      or estimated)\n- Names/entities must appear verbatim (not paraphrased or corrected)\n-
      Boolean values require explicit supporting statements\n- Lists must be complete
      based on the source (not \"including but not limited to\")\n- For relationships,
      both entities and the relationship must be explicitly stated\n\nOUTPUT RULES:\n-
      Return ONLY the extracted data in this exact format: \n\na JSON object matching
      the ''ComplexModel'' model with this schema:\n{\n  \"properties\": {\n    \"nested_data\":
      {\n      \"additionalProperties\": {\n        \"items\": {\n          \"additionalProperties\":
      {\n            \"type\": \"number\"\n          },\n          \"type\": \"object\"\n        },\n        \"type\":
      \"array\"\n      },\n      \"title\": \"Nested Data\",\n      \"type\": \"object\"\n    }\n  },\n  \"required\":
      [\n    \"nested_data\"\n  ],\n  \"title\": \"ComplexModel\",\n  \"type\": \"object\"\n}\n\n-
      No explanations, confidence scores, or meta-commentary\n- Use null/empty for
      missing data rather than placeholders\n- The entire response must be valid string
      representation of desired answer convertible to the target type\n\nUser has
      provided the following additional context (if blank, nothing provided):\n\n"},{"role":"user","content":"Extract
      some data that definitely won''t match this complex structure"},{"role":"assistant","tool_calls":[{"id":"call_zPQxbnfVH8Hs2aHwmrqAe51O","type":"function","function":{"name":"final_result","arguments":"{}"}}]},{"role":"tool","tool_call_id":"call_zPQxbnfVH8Hs2aHwmrqAe51O","content":"1
      validation errors: [\n  {\n    \"type\": \"missing\",\n    \"loc\": [\n      \"nested_data\"\n    ],\n    \"msg\":
      \"Field required\",\n    \"input\": {}\n  }\n]\n\nFix the errors and try again."}],"model":"gpt-4o-mini","stream":false,"temperature":2.0,"tool_choice":"required","tools":[{"type":"function","function":{"name":"final_result","description":"The
      final response which ends this conversation","parameters":{"properties":{"nested_data":{"additionalProperties":{"items":{"additionalProperties":{"type":"number"},"type":"object"},"type":"array"},"type":"object"}},"required":["nested_data"],"type":"object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '7016'
      content-type:
      - application/json
      cookie:
      - __cf_bm=4_gmVURDuZKY2geW67mrcJmHfSge7MQ6SQYwvcO3Rcw-1751760736-1.0.1.1-OHBOavi5r3Bj3TshtVcWhIDYemLMOc.LZZ.Zh8OP7xw7dvNPNBJfUURLqOsW68hVAMUCQMTAsp1NZRACyCHj7Ptlaw9kkWMvvPLkqb7MCRg;
        _cfuvid=nJAMzKDSO8HRLgzCw8QUEzEHfaRUzTBvizMw8371j24-1751760736988-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - pydantic-ai/0.2.16
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.81.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.11
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//zFRdb5swFH3nV1h+DlMgDSS8tdLaqVnTqWqmrlOFjLmAM2N7tqlWRfnv
        E9CAk7bSHscDMj4+5577YXYeQpjlOEGYVsTSWnH/4nd88yO+vYNHZtdX8v7q+8XqLsz0NovpFzxp
        GTLbArUH1icqa8XBMil6mGogFlrVIJ4HcRRM54sOqGUOvKWVyvpn0q+ZYH44Dc/8aewHi1d2JRkF
        gxP000MIoV33bn2KHP7gBE0nh50ajCEl4GQ4hBDWkrc7mBjDjCXC4skIUiksiNa6aDh3ACslTynh
        fAzcPztnPRaLcJ6G28elfq7KaqNnrIius/PNJXsQ0onXS7+ozlDRCDoUycGH/eQkGEJYkLrnMkF4
        qsE03J7wEcJEl00Nwrbe8W6Pj/C987Wf/FNmn1fzy2uzXn2NmvvbdXYebei3m+VD+T9nNqyfnK5q
        KBpD+Nt2EyGkJa23rt9P3kl9MJel0jIzJ9TWLjNVqoGYLi93cLyDkc4Cbo5mEysta2VTK39BFzSY
        hWEvi8cLNMKz5StopSXcpUXB5B3FNAdLWDe+w42hhFaQO9xgHg6ZkCZncsSmnlOAt47ek++LwETp
        qHwoPwKUgrKQp0pDzuhx1uMxDe0/5qNjQ6k7w9iAfmYUUstAt03JoSCHecLmxVio04KJErTSrLv+
        uFBpFJJwRhYBFNjbe38BAAD//wMAWh8FAgwFAAA=
    headers:
      CF-RAY:
      - 95aaeb9658cce7db-DFW
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 06 Jul 2025 00:17:38 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - user-54labie7aicgek5urzpgydpm
      openai-processing-ms:
      - '628'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '634'
      x-ratelimit-limit-requests:
      - '5000'
      x-ratelimit-limit-tokens:
      - '4000000'
      x-ratelimit-remaining-requests:
      - '4999'
      x-ratelimit-remaining-tokens:
      - '3998470'
      x-ratelimit-reset-requests:
      - 12ms
      x-ratelimit-reset-tokens:
      - 22ms
      x-request-id:
      - req_c4d9452fa4a1eed77eac703af0c1721b
    status:
      code: 200
      message: OK
version: 1
