from __future__ import annotations

import json
import vcr
import logging
from typing import Any
from urllib.parse import quote
from django.conf import settings

from opencontractserver.conversations.models import Conversation, ChatMessage # noqa

from channels.testing import WebsocketCommunicator
from channels.db import database_sync_to_async
from graphql_relay import to_global_id
from django.test.utils import override_settings

from opencontractserver.llms.agents import for_document
from opencontractserver.llms.types import AgentFramework
from opencontractserver.tests.base import WebsocketFixtureBaseTestCase

logging.basicConfig() # you need to initialize logging, otherwise you will not see anything from vcrpy
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
vcr_log = logging.getLogger("vcr")
vcr_log.setLevel(logging.WARNING)

@override_settings(USE_AUTH0=False)
class DocumentConversationWebsocketTestCase(WebsocketFixtureBaseTestCase):
    """
    End-to-end websocket test for the refactored DocumentQueryConsumer.
    Tests both new and loaded conversations, and a two-turn interaction.
    """

    maxDiff = None

    # Expected responses for new (not loaded from history) conversations
    expected_responses_new = {
        AgentFramework.LLAMA_INDEX.value: [
            """## Document Summary

### Title: USC Title 1 - Chapter 1

This document contains an autogenerated test summary. Please replace it with real content if needed. 

If you need more specific information or details from the document, feel free to ask!""",
            """The document titled **USC Title 1 - Chapter 1** has a brief summary, currently consisting of only 15 tokens. This indicates that the content is quite limited and likely serves as a placeholder. 

If you need further details or specific sections summarized, please let me know!""",
        ],
        AgentFramework.PYDANTIC_AI.value: [
            """I can't stream content directly, but I can help you find something to watch or listen to! What type of content are you interested in? Movies, TV shows, music, or something else? Let me know your preferences!""",
            """I would be happy to help with that! However, I currently don't have access to external documents or files. If you can provide the text or main points from the document, I can summarize it for you.""",
        ]
    }
    
    # Expected responses for conversations loaded from history
    expected_responses_loaded = {
        AgentFramework.LLAMA_INDEX.value: [
            """# Summary of USC Title 1 - Chapter 1

Autogenerated test summary – replace with real content if needed.""",
            """The summary for USC Title 1 - Chapter 1 is currently an autogenerated test summary. It suggests that the content should be replaced with more detailed and specific information if needed.""",
        ],
        AgentFramework.PYDANTIC_AI.value: [
            """It seems like you're requesting a streaming service or content. However, I can't stream media directly. I can help you find recommendations for movies, shows, or music if you'd like! What type of content are you interested in?""",
            """I'd be happy to help summarize the document! However, I don't have access to it. If you could provide the main points or sections of the document, I can help create a summary based on that information.""",
        ]
    }

    async def _assert_streaming_flow(
        self,
        communicator: WebsocketCommunicator,
        query_text: str,
        expected_response_key: str,
        is_loaded_conversation: bool = False # For logging purposes
    ) -> str:
        """
        Sends a query on an existing communicator and verifies the streaming response flow.
        """
        if is_loaded_conversation:
            logger.info(f"[_assert_streaming_flow] Testing with LOADED conversation. Query: '{query_text}'")
        else:
            logger.info(f"[_assert_streaming_flow] Testing with NEW/ANONYMOUS conversation. Query: '{query_text}'")

        # ------------------------------------------------------------------
        # Log outgoing user message (for clarity in CI logs)
        # ------------------------------------------------------------------
        current_framework_setting = str(getattr(settings, "LLMS_DOCUMENT_AGENT_FRAMEWORK", "llama_index"))
        logger.info(
            f"[TEST][framework={current_framework_setting}][loaded={is_loaded_conversation}] USER → '{query_text}'"
        )

        await communicator.send_to(json.dumps({"query": query_text}))

        received: list[dict[str, Any]] = []
        while True:
            try:
                msg = await communicator.receive_from(timeout=25) # Increased timeout for potentially longer summaries
            except Exception as e:
                self.fail(f"Timed-out waiting for websocket messages for query '{query_text}': {e}")

            payload = json.loads(msg)
            logger.debug(f"Payload for query '{query_text}': {payload}")
            received.append(payload)

            if payload.get("type") == "ASYNC_FINISH":
                break
        
        self.assertGreaterEqual(len(received), 3, f"For query '{query_text}', consumer should emit at least START, one CONTENT, FINISH.")
        self.assertEqual(received[0]["type"], "ASYNC_START", f"First message for '{query_text}' should be ASYNC_START")
        self.assertEqual(received[-1]["type"], "ASYNC_FINISH", f"Last message for '{query_text}' should be ASYNC_FINISH")

        content_msgs = [m for m in received if m["type"] == "ASYNC_CONTENT"]
        self.assertTrue(content_msgs, f"At least one ASYNC_CONTENT expected for query '{query_text}'.")
        
        full_text = "".join(msg["content"] for msg in content_msgs).strip()
        logger.info(f"[_assert_streaming_flow] Full LLM response text for query '{query_text}': {full_text}")

        # Log assistant response for easier debugging in CI logs
        logger.info(
            f"[TEST][framework={current_framework_setting}][loaded={is_loaded_conversation}] ASSISTANT ← '{full_text}'"
        )
        
        # The expected_response_key ("query1_response" or "query2_response") is used directly
        # with the selected dictionary.

        start_msg_id = received[0]["data"]["message_id"]
        self.assertTrue(start_msg_id, f"START message for '{query_text}' must contain a message_id.")

        for msg in received[1:]:
            if "data" in msg and "message_id" in msg["data"]:
                self.assertEqual(msg["data"]["message_id"], start_msg_id, f"message_id for '{query_text}' must remain constant.")

        return full_text

    async def _create_and_populate_conversation(self) -> Conversation:
        """Helper to create a conversation with a couple of messages."""
        conversation = await Conversation.objects.acreate(
            title="Pre-existing Test Conversation",
            creator=self.user,
            chat_with_document=self.doc,
        )
        await ChatMessage.objects.acreate(
            conversation=conversation,
            msg_type="HUMAN",
            content="This is a previous user message about general topics.",
            creator=self.user,
        )
        await ChatMessage.objects.acreate(
            conversation=conversation,
            msg_type="LLM",
            content="Acknowledged. I am a helpful assistant.",
            creator=self.user, # LLM messages are also created by the user in current model
        )
        logger.info(f"[_create_and_populate_conversation] Created Conversation ID: {conversation.id} with 2 messages for Document ID: {self.doc.id}")
        return conversation

    @vcr.use_cassette(
        "fixtures/vcr_cassettes/test_document_conversation_ws.yaml",
        filter_headers=["authorization"],
        record_mode="once", # Change to "rewrite" or remove cassette to re-record
    )
    async def test_multiturn_streaming_flow__all_default_frameworks(self) -> None:
        """
        Tests a two-turn streaming flow for new conversations.
        """
        print(f"--------------------------------")
        print("\n\nXOXO - [_test_multiturn_streaming_flow__all_default_frameworks] Tests a two-turn streaming flow for new conversations.")
        print(f"--------------------------------")
        
        for framework in ("llama_index", "pydantic_ai"):
            print(f"XOXO: {framework}")
            with self.subTest(default_framework=framework):
                with override_settings(
                    LLMS_DEFAULT_AGENT_FRAMEWORK=framework,
                    LLMS_DOCUMENT_AGENT_FRAMEWORK=framework,
                    LLMS_CORPUS_AGENT_FRAMEWORK=framework,
                ):
                    graphql_doc_id = to_global_id("DocumentType", self.doc.id)
                    encoded_graphql_doc_id = quote(graphql_doc_id)
                    encoded_corpus_id = quote(to_global_id("CorpusType", self.corpus.id))
                    ws_path = f"ws/document/{encoded_graphql_doc_id}/query/corpus/{encoded_corpus_id}/?token={self.token}"

                    communicator = WebsocketCommunicator(self.application, ws_path)
                    connected, _ = await communicator.connect()
                    self.assertTrue(connected, "WebSocket for new conversation should connect.")

                    response_1 = await self._assert_streaming_flow(
                        communicator=communicator, 
                        query_text="Please stream something", 
                        expected_response_key="query1_response",
                        is_loaded_conversation=False
                    )
                    response_2 = await self._assert_streaming_flow(
                        communicator=communicator, 
                        query_text="Ok, please summarize the document.", 
                        expected_response_key="query2_response",
                        is_loaded_conversation=False # Still the same new conversation
                    )
                    
                    print(f"------------------\nRESPONSES: \n\n<<{response_1}>>\n\n<<{response_2}>>\n\n------------------")
                    self.assertEqual([response_1, response_2], self.expected_responses_new[framework])

                    await communicator.disconnect()

                    # ─── NEW conversation was just created ────────────────────────────────
                    conversation = await self._fetch_last_conversation()
                    await self._log_and_assert_history(
                        conversation,
                        expected_queries=[
                            "Please stream something",
                            "Ok, please summarize the document.",
                        ],
                        expected_llm_replies=[response_1, response_2],
                    )

    @vcr.use_cassette(
        "fixtures/vcr_cassettes/test_document_conversation_ws_loaded.yaml", # Separate cassette for loaded conversations
        filter_headers=["authorization"],
        record_mode="once", # Change to "rewrite" or remove cassette to re-record
    )
    async def test_multiturn_streaming_flow_with_loaded_conversation__all_default_frameworks(self) -> None:
        """
        Tests a two-turn streaming flow when loading an existing conversation.
        """
        print(f"--------------------------------")
        print("\n\nXOXO - [_test_multiturn_streaming_flow_with_loaded_conversation] Tests a two-turn streaming flow when loading an existing conversation.")
        print(f"--------------------------------")
        
        for framework in ("llama_index", "pydantic_ai"):
            
            print(f"XOXO: {framework}")
            
            with self.subTest(default_framework=framework):
                with override_settings(
                    LLMS_DEFAULT_AGENT_FRAMEWORK=framework,
                    LLMS_DOCUMENT_AGENT_FRAMEWORK=framework,
                    LLMS_CORPUS_AGENT_FRAMEWORK=framework,
                ):
                    conversation = await self._create_and_populate_conversation()
                    
                    # Fetch history using the agent API, as requested
                    # This agent is temporary, created just to use its get_conversation_messages API
                    history_check_agent = await for_document(
                        document=self.doc,
                        corpus=self.corpus,
                        user_id=self.user.id,
                        conversation_id=conversation.id
                    )
                    actual_history_for_log = await history_check_agent.get_conversation_messages()
                    print(f"Fetched {len(actual_history_for_log)} messages via agent API for conversation {conversation.id} for logging.")
                    
                    graphql_doc_id = to_global_id("DocumentType", self.doc.id)
                    encoded_graphql_doc_id = quote(graphql_doc_id)
                    encoded_corpus_id = quote(to_global_id("CorpusType", self.corpus.id))
                    graphql_convo_id = to_global_id("ConversationType", conversation.id)
                    encoded_graphql_convo_id = quote(graphql_convo_id)
                    ws_path = f"ws/document/{encoded_graphql_doc_id}/query/corpus/{encoded_corpus_id}/?token={self.token}&load_from_conversation_id={encoded_graphql_convo_id}"

                    communicator = WebsocketCommunicator(self.application, ws_path)
                    connected, _ = await communicator.connect()
                    self.assertTrue(connected, "WebSocket for loaded conversation should connect.")

                    response_1 = await self._assert_streaming_flow(
                        communicator=communicator, 
                        query_text="Please stream something", 
                        expected_response_key="query1_response",
                        is_loaded_conversation=True
                    )
                    response_2 = await self._assert_streaming_flow(
                        communicator=communicator, 
                        query_text="Ok, please summarize the document.", 
                        expected_response_key="query2_response",
                        is_loaded_conversation=True # Still the same loaded conversation
                    )
                    print(f"------------------\nRESPONSES: \n\n<<{response_1}>>\n\n<<{response_2}>>\n\n------------------")
                    self.assertEqual([response_1, response_2], self.expected_responses_loaded[framework])

                    await communicator.disconnect()

                    # ─── NEW conversation was just created ────────────────────────────────
                    conversation = await self._fetch_last_conversation()
                    await self._log_and_assert_history(
                        conversation,
                        expected_queries=[
                            "Please stream something",
                            "Ok, please summarize the document.",
                        ],
                        expected_llm_replies=[response_1, response_2],
                        expect_prepopulated_messages=True,
                    )

    # --- Negative-path helpers and tests remain unchanged from your previous version ---
    async def _assert_invalid_token(self) -> None:
        """Connection should be rejected (code 4000) when the JWT is invalid."""
        graphql_id = to_global_id("DocumentType", self.doc.id)
        encoded_graphql_id = quote(graphql_id)
        encoded_corpus_id = quote(to_global_id("CorpusType", self.corpus.id))

        communicator = WebsocketCommunicator(
            self.application,
            f"ws/document/{encoded_graphql_id}/query/"
            f"corpus/{encoded_corpus_id}/?token=not_a_real_token",
        )
        connected, close_code = await communicator.connect()
        self.assertFalse(connected)
        self.assertEqual(close_code, 4000)

    async def _assert_missing_token(self) -> None:
        """Omitting the token entirely must also yield close 4000."""
        graphql_id = to_global_id("DocumentType", self.doc.id)
        encoded_graphql_id = quote(graphql_id)
        encoded_corpus_id = quote(to_global_id("CorpusType", self.corpus.id))

        communicator = WebsocketCommunicator(
            self.application,
            f"ws/document/{encoded_graphql_id}/query/"
            f"corpus/{encoded_corpus_id}/",
        )
        connected, close_code = await communicator.connect()
        self.assertFalse(connected)
        self.assertEqual(close_code, 4000)

    async def _assert_invalid_document(self) -> None:
        """
        A non-existent document ID should result in:
        • WebSocket *accepted*
        • Immediate `SYNC_CONTENT` error payload
        • Close code 4000
        """
        bad_doc_gid = to_global_id("DocumentType", 999_999)
        encoded_bad_doc = quote(bad_doc_gid)
        encoded_corpus_id = quote(to_global_id("CorpusType", self.corpus.id))

        communicator = WebsocketCommunicator(
            self.application,
            f"ws/document/{encoded_bad_doc}/query/"
            f"corpus/{encoded_corpus_id}/?token={self.token}",
        )
        connected, _ = await communicator.connect()
        self.assertTrue(connected)

        raw = await communicator.receive_from(timeout=25)
        payload = json.loads(raw)
        self.assertEqual(payload["type"], "SYNC_CONTENT")
        self.assertIn("error", payload["data"])
        self.assertEqual(payload["data"]["error"], "Requested Document not found.")

        # The consumer should now close the websocket with code 4000.
        close_event = await communicator.receive_output(timeout=25)
        self.assertEqual(close_event["type"], "websocket.close")
        self.assertEqual(close_event["code"], 4000)

        # Ensure the communicator is fully shut down
        await communicator.wait()

    async def test_invalid_token(self) -> None:  # noqa: D401
        """Connection rejected with an **invalid** JWT token."""
        await self._assert_invalid_token()

    async def test_missing_token(self) -> None:  # noqa: D401
        """Connection rejected when **no** JWT token is supplied."""
        await self._assert_missing_token()

    async def test_invalid_document_id(self) -> None:  # noqa: D401
        """Proper SYNC_CONTENT error for a non-existent document ID."""
        await self._assert_invalid_document()
        
    # ------------------------------------------------------------------ #
    # Utility helpers for conversation-history inspection / assertions   #
    # ------------------------------------------------------------------ #

    async def _fetch_last_conversation(self) -> Conversation:
        """
        Returns the most-recent conversation started by *this* test user
        for the current document.
        """
        return await (
            Conversation.objects.filter(
                creator=self.user, chat_with_document=self.doc
            )
            .order_by("-created_at")
            .afirst()
        )

    async def _log_and_assert_history(
        self,
        conversation: Conversation,
        expected_queries: list[str],
        expected_llm_replies: list[str],
        expect_prepopulated_messages: bool = False,
    ) -> None:
        """
        1. Dumps the complete message history to the test log.
        2. Performs a few high-level assertions to guarantee that the agent
           actually *stored* what was exchanged over the websocket.

        Args:
            conversation:   The Conversation instance to inspect.
            expected_queries:  The HUMAN contents we sent in the test.
            expected_llm_replies:  The LLM responses we asserted on.
        """
        # Pull messages – oldest first
        messages = await database_sync_to_async(list)(
            ChatMessage.objects.filter(conversation=conversation)
            .order_by("created_at")
            .all()
        )

        # --- Pretty print to console / CI logs -------------------------
        logger.info("\n====== Conversation %s – full history ======", conversation.pk)
        for msg in messages:
            logger.info(
                "[%s] %s: %s",
                msg.created_at.isoformat(timespec="seconds"),
                msg.msg_type,
                msg.content.replace("\n", " ")[:200] + ("…" if len(msg.content) > 200 else ""),
            )
        logger.info("============================================================\n")

        # --- Basic structural checks -----------------------------------
        # For a *new* conversation we expect 2 HUMAN + 2 LLM messages
        # For a *loaded* conversation we already pre-populated 2 messages.
        expected_msg_count = len(expected_queries) + len(expected_llm_replies)
        self.assertEqual(
            len(messages),
            expected_msg_count + (2 if expect_prepopulated_messages else 0),
            "Unexpected number of messages stored for conversation %s" % conversation.pk,
        )

        # # Assert the queries were stored exactly as HUMAN messages
        # human_contents = [m.content.strip() for m in messages if m.msg_type == "HUMAN"]
        # self.assertEqual(human_contents, expected_queries)

        # # Assert LLM replies were stored exactly
        # llm_contents = [m.content.strip() for m in messages if m.msg_type == "LLM"]
        # self.assertEqual(llm_contents, expected_llm_replies)
        