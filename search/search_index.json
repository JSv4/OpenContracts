{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#the-free-and-open-source-document-analytics-platform","title":"The Free and Open Source Document Analytics Platform","text":"CI/CD Meta"},{"location":"#what-does-it-do","title":"What Does it Do?","text":"<p>OpenContracts is an Apache-2 Licensed enterprise document analytics tool. It was originally designed to label and  share label document corpuses with complex layouts such as contracts, scientific papers, newspapers, etc. It has evolved into a platform for mass contract analytics that still maintains its core functionality as an open  platform that makes it effortless to view, edit and share annotations:</p> <p>|    |  | |---|---|</p> <p>Now, in the version 2 release (currently in beta) - we've incorporated LLMs and vector databases to  provide a seamless and efficient workflow for processing large volumes of documents in parallel. At the core of the system is pgvector for vector search, LlamaIndex for precise vector search and retrieval, and Marvin framework for data  parsing and extraction.</p> <p>Users can still create and edit annotations directly within the platform, enabling them to enrich documents with their  own insights and domain expertise. Through a custom LlamaIndex DjangoVectorStore, we can expose this structured data -  human annotated text with embeddings - to LLMs and the LlamaIndex ecosystem. </p> <p>Finally, the tool's intuitive interface allows for easy navigation through documents, providing clear visual cues to identify  the exact source of information extracted by the language model. This transparency ensures that users can verify the  accuracy and context of the extracted data.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>We use MkDocs for our documentation. Please visit https://JSv4.github.io/OpenContracts/ for our detailed documentation - including a quick start guide, a walk through, architectural overview and more.</p>"},{"location":"#why-does-it-exist","title":"Why Does it Exist?","text":"<p>The OpenContracts stack is designed to provide a cutting edge frontend experience while providing access to the incredible machine learning and natural language processing capabilities of Python. For this reason, our frontend is based on React. We use a GraphQL API to connect it to a django-based backend. Django is a incredibly mature, battle-tested framework that is written in Python, so integrating all the amazing Python-based AI and NLP libraries out there is super easy.</p> <p>We'd like to give credit to AllenAI's PAWLs project for our document annotating component. We rewrote most of the code base and replaced their backend entirely, so it was hard to keep , but we believe in giving credit where it's due! We are relying on their document parser, however, as it produces a really excellent text and x-y coordinate layer that we'd encourage others to use as well in similar applications that require you to interact with complex text layouts.</p>"},{"location":"#limitations","title":"Limitations","text":"<p>At the moment, it only works with PDFs. In the future, it will be able to convert other document types to PDF for storage and labeling. PDF is an excellent format for this as it introduces a consistent, repeatable format which we can use to generate a text and x-y coordinate layer from scratch. Formats like .docx and .html are too complex and varied to provide an easy, consistent format. Likewise, the output quality of many converters and tools is sub-par and these tools can produce very different document structures for the same inputs.</p> <p>Adding OCR and ingestion for other enterprise documents is a priority.</p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p>OpenContracts is built in part on top of the PAWLs project frontend. We have made extensive changes, however, and plan to remove even more of the original PAWLs codebase, particularly their state management, as it's currently duplucitive of the Apollo state store we use throughout the application. That said, PAWLs was the inspiration for how we handle text extraction, and we're planning to continue using their PDF rendering code. We are also using PAWLs' pre-processing script, which is based on Grobid.</p> <p>We should also thank the Grobid project, which was clearly a source of inspiration for PAWLs and an extremely impressive tool. Grobid is designed more for medical and scientific papers, but, nevertheless, offers a tremendous amount of inspiration and examples for the legal world to borrow. Perhaps there is an opportunity to have a unified tool in that respect.</p> <p>Finally, let's not forget Tesseract, the OCR engine that started its life as an HP research project in the 1980s before being taken over by Google in the early aughts and finally becoming an independent project in 2018. Were it not for the excellent, free OCR provided by Tesseract, we'd have to rely on commercial OCR tech, which would make this kind of opensource, free project prohibitively expensive. Thanks to the many, many people who've made free OCR possible over the nearly 40 years Tesseract has been under development.</p>"},{"location":"philosophy/","title":"Philosophy","text":""},{"location":"philosophy/#dont-repeat-yourself","title":"Don't Repeat Yourself","text":"<p>OpenContracts is designed not only be a powerful document analysis and annotation platform, it's also envisioned as a way to embrace the DRY (Don't Repeat Yourself) principle for legal and legal engineering. You can make a corpus, along with all of its labels, documents and annotations \"public\" (currently, you must do this via a GraphQL mutation).</p> <p>Once something is public, it's read-only for everyone other than its original creator. People with read-only access can \"clone\" the corpus to create a private copy of the corpus, its documents and its annotations. They can then edit the annotations, add to them, export them, etc. This lets us work from previous document annotations and re-use labels and training data.</p>"},{"location":"quick-start/","title":"Quick Start (For use on your local machine)","text":"<p>This guide is for people who want to quickly get started using the application and aren't interested in hosting it online for others to use. You'll get a default, local user with admin access. We recommend you change the user password after completing this tutorial. We assume you're using Linux or Max OS, but you could do this on Windows too, assuming you have docker compose and docker installed. The commands to create directories will be different on Windows, but the git, docker and docker-compose commands should all be the same.</p>"},{"location":"quick-start/#step-1-clone-this-repo","title":"Step 1: Clone this Repo","text":"<p>Clone the repository into a local directory of your choice. Here, we assume you are using a folder called source in your user's home directory:</p> <pre><code>    $ cd ~\n    $ mkdir source\n    $ cd source\n    $ git clone https://github.com/JSv4/OpenContracts.git\n</code></pre>"},{"location":"quick-start/#step-2-copy-sample-env-files-to-appropriate-folders","title":"Step 2: Copy sample .env files to appropriate folders","text":"<p>Again, we're assuming a local deployment here with basic options. To just get up and running, you'll want to copy our sample .env file from the <code>./docs/sample_env_files</code> directory to the appropriate folders in the repo root (for the backend) and /frontend (for the frontend).</p>"},{"location":"quick-start/#backend-env-file","title":"Backend .Env File","text":"<p>For the most basic deployment, copy ./sample_env_files/backend/local/.django to <code>./.envs/.local/.django</code> and copy ./sample_env_files/backend/local/.postgres to <code>./.envs/.local/.postgres</code>. You can use the default configurations, but we recommend you set you own admin account password in <code>.django</code> and your own postgres credentials in <code>.postgres</code>.</p>"},{"location":"quick-start/#frontend-env-file","title":"Frontend .Env File","text":"<p>You also need to copy the appropriate .env file into the <code>./frontend</code> folder. We're assuming you're not using something like auth0 and are going to rely on Django auth to provision and authenticate users. Grab ./sample_env_files/frontend/local/django.auth.env and copy it to <code>./frontend/.env</code>.</p>"},{"location":"quick-start/#step-3-build-the-stack","title":"Step 3: Build the Stack","text":"<p>Change into the directory of the repository you just cloned, e.g.:</p> <pre><code>    cd OpenContracts\n</code></pre> <p>Now, you need to build the docker compose stack. IF you are okay with the default username and password, and, most importantly, you are NOT PLANNING TO HOST THE APPLICATION online, the default, local settings are sufficient and no configuration is required. If you want to change the</p> <pre><code>    $ docker-compose -f local.yml build\n</code></pre>"},{"location":"quick-start/#step-4-choose-frontend-deployment-method","title":"Step 4 Choose Frontend Deployment Method","text":"<p>Option 1 Use \"Fullstack\" Profile in Docker Compose</p> <p>If you're not planning to do any frontend development, the easiest way to get started with OpenContracts is to just type:</p> <pre><code>    docker-compose -f local.yml --profile fullstack up\n</code></pre> <p>This will start docker compose and add a container for the frontend to the stack.</p> <p>Option 2 Use Node to Deploy Frontend</p> <p>If you plan to actively develop the frontend in the /frontend folder, you can just point your favorite typescript ID to that directory and then run:</p> <pre><code>yarn install\n</code></pre> <p>and</p> <pre><code>yarn start\n</code></pre> <p>to bring up the frontend. Then you can edit the frontend code as desired and have it hot reload as you'd expect for a React app.</p> <p>Congrats! You have OpenContracts running.</p>"},{"location":"quick-start/#step-5-login-and-start-annotating","title":"Step 5: Login and Start Annotating","text":"<p>If you go to <code>http://localhost:3000</code> in your browser, you'll see the login page. You can login with the default username and password. These are set in the environment variable file you can find in the <code>./.envs/.local/</code> directory. In that directory, you'll see a file called <code>.django</code>. Backend specific configuration variables go in there. See our guide for how to create new users.</p> <p>NOTE: The frontend is at port 3000, not 8000, so don't forget to use http://localhost:3000 for frontend access. We have an open issue to add a redirect from the backend root page - http://localhost:8000/ - to http://localhost:3000.</p> <p>Caveats</p> <p>The quick start local config is designed for use on a local machine, not for access over the Internet or a network. It uses the local disk for storage (not AWS), and Django's built-i</p>"},{"location":"requirements/","title":"System Requirements","text":""},{"location":"requirements/#system-requirements","title":"System Requirements","text":"<p>You will need Docker and Docker Compose installed to run Open Contracts. We've developed and run the application a Linux x86_64 environment. We haven't tested on Windows, and it's known that celery is not supported on Windows. For this reason, we do not recommend deployment on Windows. If you must run on a Windows machine, consider using a virtual machine or using the Windows Linux Subsystem.</p> <p>If you need help setting up Docker, we recommend Digital Ocean's setup guide. Likewise, if you need assistance setting up Docker Compose, Digital Ocean's guide is excellent.</p>"},{"location":"architecture/asynchronous-processing/","title":"Backend - Asynchronous Processing","text":""},{"location":"architecture/asynchronous-processing/#asynchronous-tasks","title":"Asynchronous Tasks","text":"<p>OpenContracts makes extensive use of celery, a powerful, mature python framework for distributed and asynchronous processing. Out-of-the-box, dedicated celeryworkers are configured in the docker compose stack to handle computationally-intensive and long-running tasks like parsing documents, applying annotations to pdfs, creating exports, importing exports, and more.</p>"},{"location":"architecture/asynchronous-processing/#what-if-my-celery-queue-gets-clogged","title":"What if my celery queue gets clogged?","text":"<p>We are always working to make OpenContracts more fault-tolerant and stable. That said, due to the nature of the types of documents we're working with - pdfs - there is tremendous variation in what the parsers have to parse. Some documents are extremely long - thousands of pages or more - whereas other documents may have poor formatting, no text layers, etc.. In most cases, OpenContracts should be able to process the pdfs and make them compatible with our annotation tools. Sometimes, however, either due to unexpected issues or unexpected volume of documents, you may want to purge the queue of tasks to be processed by your celery workers. To do this, type:</p> <pre><code>sudo docker-compose -f local.yml run django celery -A config.celery_app purge\n</code></pre> <p>Be aware that this can cause some undesired effects for your users. For example, everytime a new document is uploaded, a Django signal kicks off the pdf preprocessor to produce the PAWLs token layer that is later annotated. If these tasks are in-queue and the queue is purged, you'll have documents that are not annotatable as they'll lack the PAWLS token layers. In such cases, we recommend you delete and re-upload the documents. There are ways to manually reprocess the pdfs, but we don't have a user-friendly way to do this yet.</p>"},{"location":"architecture/under-the-hood/","title":"Backend - Architecture","text":""},{"location":"architecture/under-the-hood/#data-layers","title":"Data Layers","text":"<p>OpenContracts builds on the work that AllenAI did with PAWLs to create a consistent shared source of truth for data labeling and NLP algorithms, regardless of whether they are layout-aware, like LayoutLM or not, like BERT, Spacy or LexNLP. One of the challenges with natural language documents, particularly contracts is there are so many ways to structure any given file (e.g. .docx or .pdf) to represent exactly the same text. Even an identical document with identical formatting in a format like .pdf can have a significantly different file structure depending on what software was used to create it, the user's choices, and the software's own choices in deciding how to structure its output.</p> <p>PAWLs and OpenContracts attempt to solve this by sending every document through a processing pipeline that provides a uniform and consistent way of extracting and structuring text and layout information. Using the parsing engine of Grobid and the open source OCR engine Tesseract, every single document is re-OCRed (to produce a consistent output for the same inputs) and then the \"tokens\" (text surrounded on all sides by whitespace - typically a word) in the OCRed document are stored as JSONs with their page and positional information. In OpenContracts, we refer to this JSON layer that combines text and positional data as the \"PAWLs\" layer. We use the PAWLs layer to build the full text extract from the document as well and store this as the \"text layer\".</p> <p>Thus, in OpenContracts, every document has three files associated with it - the original pdf, a json file (the \"PAWLs layer\"), and a text file (the \"text layer\"). Because the text layer is built from the PAWLs layer, we can easily translate back and forth from text to positional information - e.g. given the start and end of a span of text the text layer, we can accurately say which PAWLs tokens the span includes, and, based on that, the x,y position of the span in the document.</p> <p>This lets us take the outputs of many NLP libraries which typically produce only start and stop ranges and layer them perfectly on top of the original pdf. With the PAWLs tokens as the source of truth, we can seamlessly transition from text only to layout-aware text.</p>"},{"location":"architecture/under-the-hood/#limitations","title":"Limitations","text":"<p>OCR is not perfect. By only accepting pdf inputs and OCRing every document, we do ignore any text embedded in the pdf. To the extent that text was exported accurately from whatever tool was used to write the document, this introduces some potential loss of fidelity - e.g. if you've ever seen an OCR engine mistake an 'O' or a 0 or 'I' for a '1' or something like that. Typically, however, the instance of such errors is fairly small, and it's a price we have to pay for the power of being able to effortlessly layer NLP outputs that have no layout awareness on top of complex, visual layouts.</p>"},{"location":"architecture/components/annotator/how-annotations-are-created/","title":"How Annotations are Handled","text":""},{"location":"architecture/components/annotator/how-annotations-are-created/#overview","title":"Overview","text":"<p>Here's a step-by-step explanation of the flow:</p> <ol> <li>The user selects text on the PDF by clicking and dragging the mouse. This triggers a mouse event in the <code>Page</code> component.</li> <li>The <code>Page</code> component checks if the Shift key is pressed.</li> <li>If the Shift key is not pressed, it creates a new selection and sets the selection state in the <code>AnnotationStore</code>.</li> <li>If the Shift key is pressed, it adds the selection to the selection queue in the <code>AnnotationStore</code>.</li> <li>The <code>AnnotationStore</code> updates its internal state with the new selection or the updated selection queue.</li> <li>If the Shift key is released, the <code>Page</code> component triggers the creation of a multi-page annotation. If the Shift key is still pressed, it waits for the next user action.</li> <li>To create a multi-page annotation, the <code>Page</code> component combines the selections from the queue.</li> <li>The <code>Page</code> component retrieves the annotation data from the <code>PDFPageInfo</code> object for each selected page.</li> <li>The <code>Page</code> component creates a <code>ServerAnnotation</code> object with the combined annotation data.</li> <li>The <code>Page</code> component calls the <code>createAnnotation</code> function in the <code>AnnotationStore</code>, passing the <code>ServerAnnotation</code> object.</li> <li>The <code>AnnotationStore</code> invokes the <code>requestCreateAnnotation</code> function in the <code>Annotator</code> component.</li> <li>The <code>Annotator</code> component sends a mutation to the server to create the annotation.</li> <li>If the server responds with success, the <code>Annotator</code> component updates the local state with the new annotation. If there's an error, it displays an error message.</li> <li>The updated annotations trigger a re-render of the relevant components, reflecting the newly created annotation on the PDF.</li> </ol>"},{"location":"architecture/components/annotator/how-annotations-are-created/#flowchart","title":"Flowchart","text":"<pre><code>graph TD\n    A[User selects text on the PDF] --&gt;|Mouse event| B(Page component)\n    B --&gt; C{Is Shift key pressed?}\n    C --&gt;|No| D[Create new selection]\n    C --&gt;|Yes| E[Add selection to queue]\n    D --&gt; F[Set selection state in AnnotationStore]\n    E --&gt; G[Update selection queue in AnnotationStore]\n    F --&gt; H{Is Shift key released?}\n    G --&gt; H\n    H --&gt;|Yes| I[Create multi-page annotation]\n    H --&gt;|No| J[Wait for next user action]\n    I --&gt; K[Combine selections from queue]\n    K --&gt; L[Get annotation data from PDFPageInfo]\n    L --&gt; M[Create ServerAnnotation object]\n    M --&gt; N[Call createAnnotation in AnnotationStore]\n    N --&gt; O[Invoke requestCreateAnnotation in Annotator]\n    O --&gt; P[Send mutation to server]\n    P --&gt; Q{Server response}\n    Q --&gt;|Success| R[Update local state with new annotation]\n    Q --&gt;|Error| S[Display error message]\n    R --&gt; T[Re-render components with updated annotations]\n</code></pre>"},{"location":"architecture/components/annotator/overview/","title":"Open Contracts Annotator Components","text":""},{"location":"architecture/components/annotator/overview/#key-questions","title":"Key Questions","text":"<ol> <li>How is the PDF loaded?</li> <li>The PDF is loaded in the <code>Annotator.tsx</code> component.</li> <li>Inside the <code>useEffect</code> hook that runs when the <code>openedDocument</code> prop changes, the PDF loading process is initiated.</li> <li>The <code>pdfjsLib.getDocument</code> function from the <code>pdfjs-dist</code> library is used to load the PDF file specified by <code>openedDocument.pdfFile</code>.</li> <li>The loading progress is tracked using the <code>loadingTask.onProgress</code> callback, which updates the <code>progress</code> state.</li> <li>Once the PDF is loaded, the <code>loadingTask.promise</code> is resolved, and the <code>PDFDocumentProxy</code> object is obtained.</li> <li> <p>The <code>PDFPageInfo</code> objects are created for each page of the PDF using <code>doc.getPage(i)</code> and stored in the <code>pages</code> state.</p> </li> <li> <p>Where and how are annotations loaded?</p> </li> <li>Annotations are loaded using the <code>REQUEST_ANNOTATOR_DATA_FOR_DOCUMENT</code> GraphQL query in the <code>Annotator.tsx</code> component.</li> <li>The <code>useQuery</code> hook from Apollo Client is used to fetch the annotator data based on the provided <code>initial_query_vars</code>.</li> <li>The <code>annotator_data</code> received from the query contains information about existing text annotations, document label annotations, and relationships.</li> <li> <p>The annotations are transformed into <code>ServerAnnotation</code>, <code>DocTypeAnnotation</code>, and <code>RelationGroup</code> objects and stored in the <code>pdfAnnotations</code> state using <code>setPdfAnnotations</code>.</p> </li> <li> <p>Where is the PAWLs layer loaded?</p> </li> <li>The PAWLs layer is loaded in the <code>Annotator.tsx</code> component.</li> <li>Inside the <code>useEffect</code> hook that runs when the <code>openedDocument</code> prop changes, the PAWLs layer is loaded using the <code>getPawlsLayer</code> function from <code>api/rest.ts</code>.</li> <li>The <code>getPawlsLayer</code> function makes an HTTP GET request to fetch the PAWLs data file specified by <code>openedDocument.pawlsParseFile</code>.</li> <li>The PAWLs data is expected to be an array of <code>PageTokens</code> objects, which contain token information for each page of the PDF.</li> <li>The loaded PAWLs data is then used to create <code>PDFPageInfo</code> objects for each page, which include the page tokens.</li> </ol>"},{"location":"architecture/components/annotator/overview/#high-level-components-overview","title":"High-level Components Overview","text":"<ul> <li>The <code>Annotator</code> component is the top-level component that manages the state and data loading for the annotator.</li> <li>It renders the <code>PDFView</code> component, which is responsible for displaying the PDF and annotations.</li> <li>The <code>PDFView</code> component renders various sub-components, such as <code>LabelSelector</code>, <code>DocTypeLabelDisplay</code>, <code>AnnotatorSidebar</code>, <code>AnnotatorTopbar</code>, and <code>PDF</code>.</li> <li>The <code>PDF</code> component renders individual <code>Page</code> components for each page of the PDF.</li> <li>Each <code>Page</code> component renders <code>Selection</code> and <code>SearchResult</code> components for annotations and search results, respectively.</li> <li>The <code>AnnotatorSidebar</code> component displays the list of annotations, relations, and a search widget.</li> <li>The <code>PDFStore</code> and <code>AnnotationStore</code> are context providers that hold the PDF and annotation data, respectively.</li> </ul>"},{"location":"architecture/components/annotator/overview/#specific-component-deep-dives","title":"Specific Component Deep Dives","text":""},{"location":"architecture/components/annotator/overview/#pdfviewtsx","title":"PDFView.tsx","text":"<p>The <code>PDFView</code> component is a top-level component that renders the PDF document with annotations, relations, and text search capabilities. It manages the state and functionality related to annotations, relations, and user interactions. Here's a detailed explanation of how the component works:</p> <ol> <li> <p>The <code>PDFView</code> component receives several props, including permissions, callbacks for CRUD operations on annotations and relations, refs for container and selection elements, and various configuration options.</p> </li> <li> <p>It initializes several state variables using the <code>useState</code> hook, including:</p> </li> <li><code>selectionElementRefs</code> and <code>searchResultElementRefs</code>: Refs for annotation selections and search results.</li> <li><code>pageElementRefs</code>: Refs for individual PDF pages.</li> <li><code>scrollContainerRef</code>: Ref for the scroll container.</li> <li><code>textSearchMatches</code> and <code>searchText</code>: State for text search matches and search text.</li> <li><code>selectedAnnotations</code> and <code>selectedRelations</code>: State for currently selected annotations and relations.</li> <li><code>pageSelection</code> and <code>pageSelectionQueue</code>: State for current page selection and queued selections.</li> <li><code>pdfPageInfoObjs</code>: State for PDF page information objects.</li> <li> <p>Various other state variables for active labels, relation modal visibility, and annotation options.</p> </li> <li> <p>The component defines several functions for updating state and handling user interactions, such as:</p> </li> <li><code>insertSelectionElementRef</code>, <code>insertSearchResultElementRefs</code>, and <code>insertPageRef</code>: Functions to add refs for selections, search results, and pages.</li> <li><code>onError</code>: Error handling callback.</li> <li><code>advanceTextSearchMatch</code> and <code>reverseTextSearchMatch</code>: Functions to navigate through text search matches.</li> <li><code>onRelationModalOk</code> and <code>onRelationModalCancel</code>: Callbacks for relation modal actions.</li> <li> <p><code>createMultiPageAnnotation</code>: Function to create a multi-page annotation from queued selections.</p> </li> <li> <p>The component uses the <code>useEffect</code> hook to handle side effects, such as:</p> </li> <li>Setting the scroll container ref on load.</li> <li>Listening for changes in the shift key and triggering annotation creation.</li> <li> <p>Updating text search matches when the search text changes.</p> </li> <li> <p>The component renders the PDF document and its related components using the <code>PDFStore</code> and <code>AnnotationStore</code> contexts:</p> </li> <li>The <code>PDFStore</code> context provides the PDF document, pages, and error handling.</li> <li> <p>The <code>AnnotationStore</code> context provides annotation-related state and functions.</p> </li> <li> <p>The component renders the following main sections:</p> </li> <li><code>LabelSelector</code>: Allows the user to select the active label for annotations.</li> <li><code>DocTypeLabelDisplay</code>: Displays the document type labels.</li> <li><code>AnnotatorSidebar</code>: Sidebar component for managing annotations and relations.</li> <li><code>AnnotatorTopbar</code>: Top bar component for additional controls and options.</li> <li> <p><code>PDF</code>: The actual PDF component that renders the PDF pages and annotations.</p> </li> <li> <p>The <code>PDF</code> component, defined in <code>PDF.tsx</code>, is responsible for rendering the PDF pages and annotations. It receives props from the <code>PDFView</code> component, such as permissions, configuration options, and callbacks.</p> </li> <li> <p>The <code>PDF</code> component maps over each page of the PDF document and renders a <code>Page</code> component for each page, passing the necessary props.</p> </li> <li> <p>The <code>Page</code> component, also defined in <code>PDF.tsx</code>, is responsible for rendering a single page of the PDF document along with its annotations and search results. It handles mouse events for creating and modifying annotations.</p> </li> <li> <p>The <code>PDFView</code> component also renders the <code>RelationModal</code> component when the active relation label is set and the user has the necessary permissions. The modal allows the user to create or modify relations between annotations.</p> </li> </ol>"},{"location":"architecture/components/annotator/overview/#pdftsx","title":"PDF.tsx","text":"<p><code>PDF</code> renders the actual PDF document with annotations and text search capabilities. PDFView (see above) is what actually interacts with the backend / API.</p> <ol> <li>The <code>PDF</code> component receives several props:</li> <li><code>shiftDown</code>: Indicates whether the Shift key is pressed (optional).</li> <li><code>doc_permissions</code> and <code>corpus_permissions</code>: Specify the permissions for the document and corpus, respectively.</li> <li><code>read_only</code>: Determines if the component is in read-only mode.</li> <li><code>show_selected_annotation_only</code>: Specifies whether to show only the selected annotation.</li> <li><code>show_annotation_bounding_boxes</code>: Specifies whether to show annotation bounding boxes.</li> <li><code>show_annotation_labels</code>: Specifies the behavior for displaying annotation labels.</li> <li><code>setJumpedToAnnotationOnLoad</code>: A callback function to set the jumped-to annotation on load.</li> <li>The <code>PDF</code> component retrieves the PDF document and pages from the <code>PDFStore</code> context.</li> <li>It maps over each page of the PDF document and renders a <code>Page</code> component for each page, passing the necessary props.</li> <li>The <code>Page</code> component is responsible for rendering a single page of the PDF document along with its annotations and search results.</li> <li>Inside the <code>Page</code> component:</li> <li>It creates a canvas element using the <code>useRef</code> hook to render the PDF page.</li> <li>It retrieves the annotations for the current page from the <code>AnnotationStore</code> context.</li> <li>It defines a <code>ConvertBoundsToSelections</code> function that converts the selected bounds to annotations and tokens.</li> <li>It uses the <code>useEffect</code> hook to set up the PDF page rendering and event listeners for resizing and scrolling.</li> <li>It renders the PDF page canvas, annotations, search results, and queued selections.</li> <li>The <code>Page</code> component renders the following sub-components:</li> <li><code>PageAnnotationsContainer</code>: A styled container for the page annotations.</li> <li><code>PageCanvas</code>: A styled canvas element for rendering the PDF page.</li> <li><code>Selection</code>: Represents a single annotation selection on the page.</li> <li><code>SearchResult</code>: Represents a search result on the page.</li> <li>The <code>Page</code> component handles mouse events for creating and modifying annotations:</li> <li>On <code>mouseDown</code>, it initializes the selection if the necessary permissions are granted and the component is not in read-only mode.</li> <li>On <code>mouseMove</code>, it updates the selection bounds if a selection is active.</li> <li>On <code>mouseUp</code>, it adds the completed selection to the <code>pageSelectionQueue</code> and triggers the creation of a multi-page annotation if the Shift key is not pressed.</li> <li>The <code>Page</code> component also handles fetching more annotations for previous and next pages using the <code>FetchMoreOnVisible</code> component.</li> <li>The <code>SelectionBoundary</code> and <code>SelectionTokens</code> components are used to render the annotation boundaries and tokens, respectively.</li> <li>The <code>PDFPageRenderer</code> class is responsible for rendering a single PDF page on the canvas. It manages the rendering tasks and provides methods for canceling and rescaling the rendering.</li> <li>The <code>getPageBoundsFromCanvas</code> function calculates the bounding box of the page based on the canvas dimensions and its parent container.</li> </ol>"},{"location":"configuration/add-users/","title":"Add Users","text":""},{"location":"configuration/add-users/#adding-more-users","title":"Adding More Users","text":"<p>You can use the same User admin page described above to create new users. Alternatively, go back to the main admin page <code>http://localhost:8000/admin</code> and, under the User section, click the \"+Add\" button:</p> <p></p> <p>Then, follow the on-screen instructions:</p> <p></p> <p>When you're done, the username and password you provided can be used to login.</p> <p>OpenContracts is currently not built to allow users to self-register unless you use the Auth0 authentication. When managing users yourself, you'll need to add, remove and modify users via the admin panels.</p>"},{"location":"configuration/choose-an-authentication-backend/","title":"Configure Authentication Backend","text":""},{"location":"configuration/choose-an-authentication-backend/#select-authentication-system-via-env-variables","title":"Select Authentication System via Env Variables","text":"<p>For authentication and authorization, you have two choices. 1. You can configure an Auth0 account and use Auth0 to authenticate users, in which case anyone    who is permitted to authenticate via your auth0 setup can login and automatically get an account, 2. or, you can require a username and password for each user and our OpenContracts backend can provide user    authentication and authorization. Using the latter option, there is no currently-supported sign-up method, you'll    need to use the admin dashboard (See \"Adding Users\" section).</p>"},{"location":"configuration/choose-an-authentication-backend/#auth0-auth-setup","title":"Auth0 Auth Setup","text":"<p>You need to configure three, separate applications on Auth0's platform:</p> <ol> <li>Configure the SPA as an application. You'll need the App Client ID.</li> <li>Configure the API. You'll need API Audience.</li> <li>Configure a M2M application to access the Auth0 Management API. This is used to fetch user details.    You'll need the API_ID for the M2M application and the Client Secret for the M2M app.</li> </ol> <p>You'll also need your Auth0 tenant ID (assuming it's the same for all three applications, though you could, in theory, host them in different tenants).  These directions are not comprehensive, so, if you're not familiar with Auth0, we recommend you disable Auth0 for the time being and use username and password.</p> <p>To enable and configure Auth0 Authentication, you'll need to set the following env variables in your .env file (the .django file in <code>.envs/.production</code> or <code>.envs/.local</code>, depending on your target environment). Our sample .envs only show these fields in the .production sample, but you could use them in the .local env file too:</p> <ol> <li><code>USE_AUTH0</code> - set to <code>true</code> to enable Auth0</li> <li><code>AUTH0_CLIENT_ID</code> - should be the client ID configured on Auth0</li> <li><code>AUTH0_API_AUDIENCE</code> - Configured API audience</li> <li><code>AUTH0_DOMAIN</code> - domain of your configured Auth0 application</li> <li><code>AUTH0_M2M_MANAGEMENT_API_SECRET</code> - secret for the auth0 Machine to Machine (M2M) API</li> <li><code>AUTH0_M2M_MANAGEMENT_API_ID</code> - ID for Auth0 Machine to Machine (M2M) API</li> <li><code>AUTH0_M2M_MANAGEMENT_GRANT_TYPE</code> - set to <code>client_credentials</code></li> </ol>"},{"location":"configuration/choose-an-authentication-backend/#detailed-explanation-of-auth0-implementation","title":"Detailed Explanation of Auth0 Implementation","text":"<p>To get Auth0 to work nicely with Graphene, we modified the graphql_jwt backend to support syncing  remote user metadata with a local user similar to the default, django <code>RemoteUserMiddleware</code>.  We're keeping the graphql_jwt graphene middleware in its entirety as it fetches the  token and then passes it along to django authentication *backend. That django backend  is what we're modifying to decode the jwt token against Auth0 settings and then check to see if local user exists, and, if not, create it.</p> <p>Here's the order of operations in the original Graphene backend provided by graphql_jwt:</p> <ol> <li>Backend's <code>authenticate</code> method is called from the graphene middleware via django (from django.contrib.auth    import authenticate)</li> <li>token is retrieved via .utils get_credentials</li> <li>if token is not None, get_user_by_token in shortcuts module is called<ol> <li>\"Payload\" is retrieved via utils.get_payload</li> <li>User is requested via utils.get_user_by_payload</li> <li>username is retrieved from payload via <code>auth0_settings.JWT_PAYLOAD_GET_USERNAME_HANDLER</code></li> <li>user object is retrieved via <code>auth0_settings.JWT_GET_USER_BY_NATURAL_KEY_HANDLER</code></li> </ol> </li> </ol> <p>We modified a couple things:</p> <ol> <li>The decode method called in 3(a) needs to be modified to decode with Auth0 secrets and settings.</li> <li>get_user_by_payload needs to be modified in several ways:<ol> <li>user object must use <code>RemoteUserMiddleware</code> logic and, if everything from auth0 decodes properly,       check to see if user with e-mail exists and, if not, create it. Upon completion of this,       try to sync user data with auth0. 2) return created or retrieved user object as original method did</li> </ol> </li> </ol>"},{"location":"configuration/choose-an-authentication-backend/#django-based-authentication-setup","title":"Django-Based Authentication Setup","text":"<p>The only thing you need to do for this is toggle the two auth0-related environment variables: 1. For the backend environment, set <code>USE_AUTH0=False</code> in your environment (either via an environment variable file or    directly in your environment via the console). 2. For the frontend environment, set <code>REACT_APP_USE_AUTH0=false</code> in your environment (either via an environment variable file or    directly in your environment via the console).</p> <p>Note</p> <p>As noted elsewhere, users cannot sign up on their own. You need to log into the admin dashboard - e.g. <code>http://localhost:8000/admin</code> - and add users manually.</p>"},{"location":"configuration/choose-and-configure-docker-stack/","title":"Choose and Configure Docker Compose Stack","text":""},{"location":"configuration/choose-and-configure-docker-stack/#deployment-options","title":"Deployment Options","text":"<p>OpenContracts is designed to be deployed using docker-compose. You can run it locally or in a production environment. Follow the instructions below for a local environment if you just want to test it or you want to use it for yourself and don't intend to make the application available to other users via the Internet.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#local-deployment","title":"Local Deployment","text":""},{"location":"configuration/choose-and-configure-docker-stack/#quick-start-with-default-settings","title":"Quick Start with Default Settings","text":"<p>A \"local\" deployment is deployed on your personal computer and is not meant to be accessed over the Internet. If you don't need to configure anything, just follow the quick start guide above to get up and running with a local deployment without needing any further configuration.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#setup-env-files","title":"Setup .env Files","text":""},{"location":"configuration/choose-and-configure-docker-stack/#backend","title":"Backend","text":"<p>After cloning this repo to a machine of your choice, create a folder for your environment files in the repo root. You'll need <code>./.envs/.local/.django</code> and <code>./.envs/.local/.postgres</code> Use the samples in <code>./documentation/sample_env_files/local</code> as guidance. NOTE, you'll need to replace the placeholder passwords and users where noted, but, otherwise, minimal config should be required.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#frontend","title":"Frontend","text":"<p>In the <code>./frontend</code> folder, you also need to create a single .env file which holds your configurations for your login method as well as certain feature switches (e.g. turn off imports). We've included a sample using auth0 and another sample using django's auth backend. Local vs production deployments are essentially the same, but the root url of the backend will change from localhost to whereever you're hosting the application in production.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#build-the-stack","title":"Build the Stack","text":"<p>Once your .env files are setup, build the stack using docker-compose:</p> <p><code>$ docker-compose -f local.yml build</code></p> <p>Then, run migrations (to setup the database):</p> <p><code>$ docker-compose -f local.yml run django python manage.py migrate</code></p> <p>Then, create a superuser account that can log in to the admin dashboard (in a local deployment this is available at <code>http://localhost:8000/admin</code>) by typing this command and following the prompts:</p> <pre><code>$ docker-compose -f local.yml run django python manage.py createsuperuser\n</code></pre> <p>Finally, bring up the stack:</p> <pre><code>$ docker-compose -f local.yml up\n</code></pre> <p>You should now be able to access the OpenContracts frontend by visiting <code>http://localhost:3000</code>.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#production-environment","title":"Production Environment","text":"<p>The production environment is designed to be public-facing and exposed to the Internet, so there are quite a number more configurations required than a local deployment, particularly if you use an AWS S3 storage backend or the Auth0 authentication system.</p> <p>After cloning this repo to a machine of your choice, configure the production .env files as described above.</p> <p>You'll also need to configure your website url. This needs to be done in a few places.</p> <p>First, in <code>opencontractserver/contrib/migrations</code>, you'll fine a file called <code>0003_set_site_domain_and_name.py</code>. BEFORE  running any of your migrations, you should modify the <code>domain</code> and <code>name</code> defaults you'll fine in <code>update_site_forward</code>:</p> <pre><code>def update_site_forward(apps, schema_editor):\n \"\"\"Set site domain and name.\"\"\" Site = apps.get_model(\"sites\", \"Site\") Site.objects.update_or_create( id=settings.SITE_ID, defaults={ \"domain\": \"opencontracts.opensource.legal\", \"name\": \"OpenContractServer\", }, )\n</code></pre> <p>and <code>update_site_backward</code>:</p> <pre><code>def update_site_backward(apps, schema_editor):\n \"\"\"Revert site domain and name to default.\"\"\" Site = apps.get_model(\"sites\", \"Site\") Site.objects.update_or_create( id=settings.SITE_ID, defaults={\"domain\": \"example.com\", \"name\": \"example.com\"} )\n</code></pre> <p>Finally, don't forget to configure Treafik, the router in the docker-compose stack that exposes different containers to end-users depending on the route (url) received you need to update the Treafik file here.</p> <p>If you're using Auth0, see the Auth0 configuration section.</p> <p>If you're using AWS S3 for file storage, see the AWS configuration section. NOTE, the underlying django library that provides cloud storage, django-storages, can also work with other cloud providers such as Azure and GCP. See the django storages library docs for more info.</p> <pre><code>$ docker-compose -f production.yml build\n</code></pre> <p>Then, run migrations (to setup the database):</p> <pre><code>$ docker-compose -f production.yml run django python manage.py migrate`\n</code></pre> <p>Then, create a superuser account that can log in to the admin dashboard (in a production deployment this is available at the url set in your env file as the <code>DJANGO_ADMIN_URL</code>) by typing this command and following the prompts:</p> <pre><code>$ docker-compose -f production.yml run django python manage.py createsuperuser\n</code></pre> <p>Finally, bring up the stack:</p> <pre><code>$ docker-compose -f production.yml up\n</code></pre> <p>You should now be able to access the OpenContracts frontend by visiting <code>http://localhost:3000</code>.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#env-file-configurations","title":"ENV File Configurations","text":"<p>OpenContracts is configured via .env files. For a local deployment, these should go in <code>.envs/.local</code>. For production, use <code>.envs/.production</code>. Sample .envs for each deployment environment are provided in <code>documentation/sample_env_files</code>.</p> <p>The local configuration should let you deploy the application on your PC without requiring any specific configuration. The production configuration is meant to provide a web application and requires quite a bit more configuration and knowledge of web apps.</p>"},{"location":"configuration/choose-and-configure-docker-stack/#include-gremlin","title":"Include Gremlin","text":"<p>If you want to include a Gremlin analyzer, use <code>local_deploy_with_gremlin.yml</code> or <code>production_deploy_with_gremlin.yml</code> instead of <code>local.yml</code> or <code>production.yml</code>, respectively. All other parts of the tutorial are the same.</p>"},{"location":"configuration/choose-storage-backend/","title":"Configure Storage Backend","text":""},{"location":"configuration/choose-storage-backend/#select-and-setup-storage-backend","title":"Select and Setup Storage Backend","text":"<p>You can use Amazon S3 as a file storage backend (if you set the env flag <code>USE_AWS=True</code>, more on that below), or you can use the local storage of the host machine via a Docker volume.</p>"},{"location":"configuration/choose-storage-backend/#aws-storage-backend","title":"AWS Storage Backend","text":"<p>If you want to use AWS S3 to store files (primarily pdfs, but also exports, tokens and txt files), you will need an Amazon AWS account to setup S3. This README does not cover the AWS side of configuration, but there  are a number of tutorials and guides to getting AWS configured to be used with a django project.</p> <p>Once you have an S3 bucket configured, you'll need to set the following env variables in your .env file (the <code>.django</code> file in <code>.envs/.production</code> or <code>.envs/.local</code>, depending on your target environment). Our sample .envs only show these fields in the .production samples, but you could use them in the .local env file too.</p> <p>Here the variables you need to set to enable AWS S3 storage:</p> <ol> <li><code>USE_AWS</code> - set to <code>true</code> since you're using AWS, otherwise the backend will use a docker volume for storage.</li> <li><code>DJANGO_AWS_ACCESS_KEY_ID</code> - the access key ID created by AWS when you set up your IAM user (see tutorials above).</li> <li><code>DJANGO_AWS_SECRET_ACCESS_KEY</code> - the secret access key created by AWS when you set up your IAM user    (see tutorials above)</li> <li><code>DJANGO_AWS_STORAGE_BUCKET_NAME</code> - the name of the AWS bucket you created to hold the files.</li> <li><code>DJANGO_AWS_S3_REGION_NAME</code> - the region of the AWS bucket you configured.</li> </ol>"},{"location":"configuration/choose-storage-backend/#django-storage-backend","title":"Django Storage Backend","text":"<p>Setting <code>USE_AWS=false</code> will use the disk space in the django container. When using the local docker compose stack, the celery workers and django containers share the same disk, so this works fine. Our production configuration would not work properly with <code>USE_AWS=false</code>, however, as each container has its own disk.</p>"},{"location":"configuration/configure-admin-users/","title":"Configure Admin Users","text":""},{"location":"configuration/configure-admin-users/#gremlin-admin-dashboard","title":"Gremlin Admin Dashboard","text":"<p>Gremlin's backend is built on Django, which has its own powerful admin dashboard. This dashboard is not meant for end-users and should only be used by admins. You can access the admin dashboard by going to the <code>/admin</code> page - e,g, <code>opencontracts.opensource.legal/admin</code> or <code>http://localhost:8000/admin</code>. For the most part, you shouldn't need to use the admin dashboard and should only go in here if you're experience errors or unexpected behavior and want to look at the detailed contents of the database to see if it sheds any light on what's happening with a give corpus, document, etc.</p> <p>By default, Gremlin creates an admin user for you. If you don't specify the username and password in your environment on first boot, it'll use system defaults. You can customize the default username and password via environment variables or after the system boots using the admin dash.</p>"},{"location":"configuration/configure-admin-users/#configure-username-and-password-prior-to-first-deployment","title":"Configure Username and Password Prior to First Deployment","text":"<p>If the variable <code>DJANGO_SUPERUSER_USERNAME</code> is set, that will be the default admin user created on startup (the first time your run <code>docker-compose -f local.yml up</code>). The repo ships with a default superuser username of <code>admin</code>. The default password is set using the <code>DJANGO_SUPERUSER_PASSWORD</code> variable. The environment files for local deployments (but not production) include a default password of <code>Openc0ntracts_def@ult</code>. You should change this in the environment file before the first start OR, follow the instructions below to change it after the first start.</p> <p>If you modify these environment variables in the environment file BEFORE running the docker-compose <code>up</code> command for the first time, your initial superuser will have the username, email and/or password you specify. If you don't modify the defaults, you can change them after you have created them via the admin dashboard (see below).</p>"},{"location":"configuration/configure-admin-users/#after-first-deployment-via-admin-dashboard","title":"After First Deployment via Admin Dashboard","text":"<p>Once the default superuser has been created, you'll need to use the admin dashboard to modify it.</p> <p>To manage users, including changing the password, you'll need to access the backend admin dashboard. OpenContracts is built on Django, which ships with Django Admin, a tool to manage low-level object data and users. It doesn't provide the rich, document focused UI/UX our frontend does, but it does let you edit and delete objects created on the frontend if, for any reason, you are unable to fix something done by a frontend user (e.g. a corrupt file is uploaded and cannot be parsed or rendered properly on the frontend).</p> <p>To update your users, first login to the admin panel:</p> <p></p> <p>Then, in the lefthand navbar, find the entry for \"Users\" and click on it</p> <p></p> <p>Then, you'll see a list of all users for this instance. You should see your admin user and an \"Anonymous\" user. The Anonymous user is required for public browsing of objcets with their <code>is_public</code> field set to True. The Anonymous user cannot see other objects.</p> <p></p> <p>Click on the admin user to bring up the detailed user view:</p> <p></p> <p>Now you can click the \"WHAT AM I CALLED\" button to bring up a dialog to change the user password.</p>"},{"location":"configuration/configure-gremlin/","title":"Configure Gremlin Analyzer","text":"<p>Gremlin is a separate project by OpenSource Legal to provide a standard API to access NLP capabilities. This lets us wrap multiple NLP engines / techniques in the same API which lets us build tools that can readily consume the outputs of very different NLP libraries (etc. a Transformers-based model like BERT, and tools like SPACY and LexNLP can be deployed on Gremlin and the outputs from all three can readily be rendered in OpenContracts).</p> <p>OpenContracts is designed to work with Gremlin out-of-the-box. We have a sample compose yaml file showing how to do this on a local machine <code>local_deploy_with_gremlin.yaml</code> and as a web-facing application <code>production_deploy_with_gremlin.yaml</code>.</p> <p>When you add a new Gremlin Engine to the database, OpenContracs will automatically query it for its installed analyzers and labels. These will then be available within OpenContracts, and you can use an analyzer to analyze any OpenContracts corpus.</p> <p>While we have plans to automatically \"install\" the default Gremlin on first boot, currently you must manually go into the OpenContracts admin dash and add the Gremlin. Thankfully, this is an easy process:</p> <ol> <li>In your environment file, make sure you set <code>CALLBACK_ROOT_URL_FOR_ANALYZER</code><ol> <li>For local deploy, use <code>CALLBACK_ROOT_URL_FOR_ANALYZER=http://localhost:8000</code></li> <li>For production deploy, use <code>http://django:5000</code>. Why the change? Well, in our local       docker compose stack, the host the localhost and the django development server runs on port 8000. In       production, we want Gremlin to communicate with the OpenContracts container (\"django\") via its       hostname on the docker compose stack's network. The production OpenContracts container also uses       gunicorn on port 5000 instead of the development server on port 8000, so the port changes too.</li> </ol> </li> <li>Go to the admin page:    </li> <li>Click \"Add+\" in the Gremlin row to bring up the Add Gremlin Engine form. You just need to set the creator    Url fields (the url for our default config is <code>http://gremlinengine:5000</code>). If, for some reason, you don't want    the analyzer to be visible to any unauthenticated user, unselect the <code>is_public</code> box :    </li> <li>This will automatically kick off an install process that runs in the background. When it's complete, you'll see the    \"Install Completed\" Field change. It should take a second or two. At the moment, we don't handle errors in this    process, so, if it doesn't complete successfully in 30 seconds, there is probably a misconfiguration somewhere. We    plan to improve our error handling for these backend installation processes.</li> </ol> <p>Note, in our example implementations, Gremlin is NOT encrypted or API Key secured to outside traffic. It's not exposed to outside traffic either per our docker compose config, so this shouldn't be a major concern. If you do expose the container to the host via your Docker Compose file, you should ensure you run the traffic through Treafik and setup API Key authentication.</p>"},{"location":"development/documentation/","title":"Documentation","text":""},{"location":"development/documentation/#documentation-stack","title":"Documentation Stack","text":"<p>We're using mkdocs to render our markdown into pretty, bite-sized pieces. The markdown lives in <code>/docs</code> in our repo. If you want to work on the docs you'll need to install the requirements in <code>/requirements/docs.txt</code>.</p> <p>To have a live server while working on them, type:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"development/documentation/#building-docs","title":"Building Docs","text":"<p>To build a html website from your markdown that can be uploaded to a webhost (or a GitHub Page), just type:</p> <pre><code>mkdocs build\n</code></pre>"},{"location":"development/documentation/#deploying-to-gh-page","title":"Deploying to GH Page","text":"<p>mkdocs makes it super easy to deploy your docs to a GitHub page.</p> <p>Just run:</p> <pre><code>mkdocs gh-deploy\n</code></pre>"},{"location":"development/environment/","title":"Dev Environment","text":"<p>We use Black and Flake8 for Python Code Styling. These are run via pre-commit before all commits. If you want to develop extensions or code based on OpenContracts, you'll need to setup pre-commit. First, make sure the requirements in <code>./requirements/local.txt</code> are installed in your local environment.</p> <p>Then, install pre-commit into your local git repo. From the root of the repo, run:</p> <p><pre><code> $ pre-commit install\n</code></pre> If you want to run pre-commit manually on all the code in the repo, use this command:</p> <pre><code> $ pre-commit run --all-files\n</code></pre> <p>When you commit changes to your repo or our repo as a PR, pre-commit will run and ensure your code follows our style guide and passes linting.</p>"},{"location":"development/frontend-notes/","title":"Frontend Notes","text":""},{"location":"development/frontend-notes/#responsive-layout","title":"Responsive Layout","text":"<p>The application was primarily designed to be viewed around 1080p. We've built in some quick and dirty (honestly, hacks) to display a usable layout at other resolutions. A more thorough redesign / refactor is in order, again if there's sufficient interest. What's available now should handle a lot of situations ok. If you find performance / layout is not looking great at your given resolution, try to use a desktop browser at a 1080p resolution.</p>"},{"location":"development/frontend-notes/#no-test-suite","title":"No Test Suite","text":"<p>As of our initial release, the test suite only tests the backend (and coverage is admittedly not as robust as we'd like). We'd like to add tests for the frontend, though this is a fairly large undertaking. We welcome any contributions on this front!</p>"},{"location":"development/test-suite/","title":"Test Suite","text":"<p>Our test suite is a bit sparse, but we're working to improve coverage on the backend. Frontend tests will likely take longer to implement. Our existing tests do test imports and a number of the utility functions for manipulating annotations. These tests are integrated in our GitHub actions.</p> <p>NOTE, use Python 3.10 or above as pydantic and certain pre-3.10 type annotations do not play well. using <code>from __future__ import annotations</code> doesn't always solve the problem, and upgrading to Python 3.10 was a lot easier than trying to figure out why the <code>from __future__</code> didn't behave as expected</p> <p>To run the tests, check your test coverage, and generate an HTML coverage report:</p> <pre><code> $ docker-compose -f local.yml run django coverage run -m pytest\n $ docker-compose -f local.yml run django coverage html\n $ open htmlcov/index.html\n</code></pre> <p>To run a specific test (e.g. test_analyzers):</p> <pre><code> $ sudo docker-compose -f local.yml run django python manage.py test opencontractserver.tests.test_analyzers --noinput\n</code></pre>"},{"location":"extract_and_retrieval/document_data_extract/","title":"Extracting Structured Data from Documents using LlamaIndex, AI Agents, and Marvin","text":"<p>We've added a powerful feature called \"extract\" that enables the generation of structured data grids from a list of documents using a combination of vector search, AI agents, and the Marvin library.</p> <p>This <code>run_extract</code> task orchestrates the extraction process, spinning up a number of <code>llama_index_doc_query</code> tasks. Each of these query tasks uses LlamaIndex Django &amp; pgvector for vector search and retrieval, and Marvin for data parsing and extraction. It processes each document and column in parallel using celery's task system.</p> <p>All credit for the inspiration of this feature goes to the fine folks at Nlmatics. They were some of the first pioneers working on datagrids from document using a set of questions and custom transformer models. This implementation of their concept ultimately leverages newer techniques and better models, but hats off to them for coming up with a design like this in 2017/2018!</p> <p>The current implementation relies heavily on LlamaIndex, specifically their vector store tooling, their reranker and their agent framework.</p> <p>Structured data extraction is powered by the amazing Marvin library.</p>"},{"location":"extract_and_retrieval/document_data_extract/#overview","title":"Overview","text":"<p>The extract process involves the following key components:</p> <ol> <li>Document Corpus: A collection of documents from which structured data will be extracted.</li> <li>Fieldset: A set of columns defining the structure of the data to be extracted.</li> <li>LlamaIndex: A library used for efficient vector search and retrieval of relevant document sections.</li> <li>AI Agents: Intelligent agents that analyze the retrieved document sections and extract structured data.</li> <li>Marvin: A library that facilitates the parsing and extraction of structured data from text.</li> </ol> <p>The extract process is initiated by creating an <code>Extract</code> object that specifies the document corpus and the fieldset defining the desired data structure. The process is then broken down into individual tasks for each document and column combination, allowing for parallel processing and scalability.</p>"},{"location":"extract_and_retrieval/document_data_extract/#detailed-walkthrough","title":"Detailed Walkthrough","text":"<p>Here's how the extract process works step by step.</p>"},{"location":"extract_and_retrieval/document_data_extract/#1-initiating-the-extract-process","title":"1. Initiating the Extract Process","text":"<p>The <code>run_extract</code> function is the entry point for initiating the extract process. It takes the <code>extract_id</code> and <code>user_id</code> as parameters and performs the following steps:</p> <ol> <li>Retrieves the <code>Extract</code> object from the database based on the provided <code>extract_id</code>.</li> <li>Sets the <code>started</code> timestamp of the extract to the current time.</li> <li>Retrieves the <code>fieldset</code> associated with the extract, which defines the columns of the structured data grid.</li> <li>Retrieves the list of document IDs associated with the extract.</li> <li>Creates <code>Datacell</code> objects for each document and column combination, representing the individual cells in the structured data grid.</li> <li>Sets the appropriate permissions for each <code>Datacell</code> object based on the user's permissions.</li> <li>Kicks off the processing job for each <code>Datacell</code> by appending a task to the Celery task queue.</li> </ol>"},{"location":"extract_and_retrieval/document_data_extract/#2-processing-individual-datacells","title":"2. Processing Individual Datacells","text":"<p>The <code>llama_index_doc_query</code> function is responsible for processing each individual <code>Datacell</code>.</p>"},{"location":"extract_and_retrieval/document_data_extract/#execution-flow-visualized","title":"Execution Flow Visualized:","text":"<pre><code>graph TD\n    I[llama_index_doc_query] --&gt; J[Retrieve Datacell]\n    J --&gt; K[Create HuggingFaceEmbedding]\n    K --&gt; L[Create OpenAI LLM]\n    L --&gt; M[Create DjangoAnnotationVectorStore]\n    M --&gt; N[Create VectorStoreIndex]\n    N --&gt; O{Special character '|||' in search_text?}\n    O -- Yes --&gt; P[Split examples and average embeddings]\n    P --&gt; Q[Query annotations using averaged embeddings]\n    Q --&gt; R[Rerank nodes using SentenceTransformerRerank]\n    O -- No --&gt; S[Retrieve results using index retriever]\n    S --&gt; T[Rerank nodes using SentenceTransformerRerank]\n    R --&gt; U{Column is agentic?}\n    T --&gt; U\n    U -- Yes --&gt; V[Create QueryEngineTool]\n    V --&gt; W[Create FunctionCallingAgentWorker]\n    W --&gt; X[Create StructuredPlannerAgent]\n    X --&gt; Y[Query agent for definitions]\n    U -- No --&gt; Z{Extract is list?}\n    Y --&gt; Z\n    Z -- Yes --&gt; AA[Extract with Marvin]\n    Z -- No --&gt; AB[Cast with Marvin]\n    AA --&gt; AC[Save result to Datacell]\n    AB --&gt; AC\n    AC --&gt; AD[Mark Datacell complete]\n</code></pre>"},{"location":"extract_and_retrieval/document_data_extract/#step-by-step-walkthrough","title":"Step-by-step Walkthrough","text":"<ol> <li> <p>The <code>run_extract</code> task is called with an <code>extract_id</code> and <code>user_id</code>. It retrieves the corresponding <code>Extract</code> object and marks it as started.</p> </li> <li> <p>It then iterates over the document IDs associated with the extract. For each document and each column in the extract's fieldset, it:</p> </li> <li>Creates a new <code>Datacell</code> object with the extract, column, output type, creator, and document.</li> <li>Sets CRUD permissions for the datacell to the user.</li> <li> <p>Appends a <code>llama_index_doc_query</code> task to a list of tasks, passing the datacell ID.</p> </li> <li> <p>After all datacells are created and their tasks added to the list, a Celery <code>chord</code> is used to group the tasks. Once all tasks are complete, it calls the <code>mark_extract_complete</code> task to mark the extract as finished.</p> </li> <li> <p>The <code>llama_index_doc_query</code> task processes each individual datacell. It:</p> </li> <li>Retrieves the datacell and marks it as started.</li> <li>Creates a <code>HuggingFaceEmbedding</code> model and sets it as the <code>Settings.embed_model</code>.</li> <li>Creates an <code>OpenAI</code> LLM and sets it as the <code>Settings.llm</code>.</li> <li>Creates a <code>DjangoAnnotationVectorStore</code> from the document ID and column settings.</li> <li> <p>Creates a <code>VectorStoreIndex</code> from the vector store.</p> </li> <li> <p>If the <code>search_text</code> contains the special character '|||':</p> </li> <li>It splits the examples and calculates the embeddings for each example.</li> <li>It calculates the average embedding from the individual embeddings.</li> <li>It queries the <code>Annotation</code> objects using the averaged embeddings and orders them by cosine distance.</li> <li>It reranks the nodes using <code>SentenceTransformerRerank</code> and retrieves the top-n nodes.</li> <li>It adds the annotation IDs of the reranked nodes to the datacell's sources.</li> <li> <p>It retrieves the text from the reranked nodes.</p> </li> <li> <p>If the <code>search_text</code> does not contain the special character '|||':</p> </li> <li>It retrieves the relevant annotations using the index retriever based on the <code>search_text</code> or <code>query</code>.</li> <li>It reranks the nodes using <code>SentenceTransformerRerank</code> and retrieves the top-n nodes.</li> <li>It adds the annotation IDs of the reranked nodes to the datacell's sources.</li> <li> <p>It retrieves the text from the retrieved nodes.</p> </li> <li> <p>If the column is marked as <code>agentic</code>:</p> </li> <li>It creates a <code>QueryEngineTool</code>, <code>FunctionCallingAgentWorker</code>, and <code>StructuredPlannerAgent</code>.</li> <li>It queries the agent to find defined terms and section references in the retrieved text.</li> <li> <p>The definitions and section text are added to the retrieved text.</p> </li> <li> <p>Depending on whether the column's <code>extract_is_list</code> is true, it either:</p> </li> <li>Extracts a list of the <code>output_type</code> from the retrieved text using Marvin, with optional <code>instructions</code> or <code>query</code>.</li> <li> <p>Casts the retrieved text to the <code>output_type</code> using Marvin, with optional <code>instructions</code> or <code>query</code>.</p> </li> <li> <p>The result is saved to the datacell's <code>data</code> field based on the <code>output_type</code>. The datacell is marked as completed.</p> </li> <li> <p>If an exception occurs during processing, the error is logged, saved to the datacell's <code>stacktrace</code>, and the     datacell is marked as failed.</p> </li> </ol>"},{"location":"extract_and_retrieval/document_data_extract/#next-steps","title":"Next Steps","text":"<p>This is more of a proof-of-concept of the power of the existing universe of open source tooling. There are a number of more advanced techniques we can use to get better retrieval, more intelligent agentic behavior and more. Also, we haven't optomized for performance AT ALL, so any improvements in any of these areas would be welcome. Further, we expect the real power for an open source tool like OpenContracts to come from custom implementations of this functionality, so we'll also be working on more easily customizable and modular agents and retrieval pipelines so you can quickly select the right pipeline for the right task.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/","title":"Making a Django Application Compatible with LlamaIndex using a Custom Vector Store","text":""},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#introduction","title":"Introduction","text":"<p>In this walkthrough, we'll explore how the custom <code>DjangoAnnotationVectorStore</code> makes a Django application compatible with LlamaIndex, enabling powerful vector search capabilities within the application's structured annotation store. By leveraging the <code>BasePydanticVectorStore</code> class provided by LlamaIndex and integrating it with Django's ORM and the <code>pg-vector</code> extension for PostgreSQL, we can achieve efficient and scalable vector search functionality.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#understanding-the-djangoannotationvectorstore","title":"Understanding the <code>DjangoAnnotationVectorStore</code>","text":"<p>The <code>DjangoAnnotationVectorStore</code> is a custom implementation of LlamaIndex's <code>BasePydanticVectorStore</code> class, tailored specifically for a Django application. It allows the application to store and retrieve granular, visually-locatable annotations (x-y blocks) from PDF pages using vector search.</p> <p>Let's break down the key components and features of the <code>DjangoAnnotationVectorStore</code>:</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#1-inheritance-from-basepydanticvectorstore","title":"1. Inheritance from <code>BasePydanticVectorStore</code>","text":"<pre><code>class DjangoAnnotationVectorStore(BasePydanticVectorStore):\n    ...\n</code></pre> <p>By inheriting from <code>BasePydanticVectorStore</code>, the <code>DjangoAnnotationVectorStore</code> gains access to the base functionality and interfaces provided by LlamaIndex for vector stores. This ensures compatibility with LlamaIndex's query engines and retrieval methods.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#2-integration-with-djangos-orm","title":"2. Integration with Django's ORM","text":"<p>The <code>DjangoAnnotationVectorStore</code> leverages Django's Object-Relational Mapping (ORM) to interact with the application's database. It defines methods like <code>_get_annotation_queryset()</code> and <code>_build_filter_query()</code> to retrieve annotations from the database using Django's queryset API.</p> <pre><code>def _get_annotation_queryset(self) -&gt; QuerySet:\n    queryset = Annotation.objects.all()\n    if self.corpus_id is not None:\n        queryset = queryset.filter(\n            Q(corpus_id=self.corpus_id) | Q(document__corpus=self.corpus_id)\n        )\n    if self.document_id is not None:\n        queryset = queryset.filter(document=self.document_id)\n    if self.must_have_text is not None:\n        queryset = queryset.filter(raw_text__icontains=self.must_have_text)\n    return queryset.distinct()\n</code></pre> <p>This integration allows seamless retrieval of annotations from the Django application's database, making it compatible with LlamaIndex's querying and retrieval mechanisms.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#3-utilization-of-pg-vector-for-vector-search","title":"3. Utilization of <code>pg-vector</code> for Vector Search","text":"<p>The <code>DjangoAnnotationVectorStore</code> utilizes the <code>pg-vector</code> extension for PostgreSQL to perform efficient vector search operations. <code>pg-vector</code> adds support for vector data types and provides optimized indexing and similarity search capabilities.</p> <pre><code>queryset = (\n    queryset.order_by(\n        CosineDistance(\"embedding\", query.query_embedding)\n    ).annotate(\n        similarity=CosineDistance(\"embedding\", query.query_embedding)\n    )\n)[: query.similarity_top_k]\n</code></pre> <p>In the code above, the <code>CosineDistance</code> function from <code>pg-vector</code> is used to calculate the cosine similarity between the query embedding and the annotation embeddings stored in the database. This allows for fast and accurate retrieval of relevant annotations based on vector similarity.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#4-customization-and-filtering-options","title":"4. Customization and Filtering Options","text":"<p>The <code>DjangoAnnotationVectorStore</code> provides various customization and filtering options to fine-tune the vector search process. It allows filtering annotations based on criteria such as <code>corpus_id</code>, <code>document_id</code>, and <code>must_have_text</code>.</p> <pre><code>def _build_filter_query(self, filters: Optional[MetadataFilters]) -&gt; QuerySet:\n    queryset = self._get_annotation_queryset()\n\n    if filters is None:\n        return queryset\n\n    for filter_ in filters.filters:\n        if filter_.key == \"label\":\n            queryset = queryset.filter(annotation_label__text__iexact=filter_.value)\n        else:\n            raise ValueError(f\"Unsupported filter key: {filter_.key}\")\n\n    return queryset\n</code></pre> <p>This flexibility enables targeted retrieval of annotations based on specific metadata filters, enhancing the search capabilities of the application.</p>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#benefits-of-integrating-llamaindex-with-django","title":"Benefits of Integrating LlamaIndex with Django","text":"<p>Integrating LlamaIndex with a Django application using the <code>DjangoAnnotationVectorStore</code> offers several benefits:</p> <ol> <li>Structured Annotation Storage: The Django application's annotation store provides a structured and organized way to store and manage granular annotations extracted from PDF pages. Each annotation is associated with metadata such as page number, bounding box coordinates, and labels, allowing for precise retrieval and visualization.</li> <li>Efficient Vector Search: By leveraging the <code>pg-vector</code> extension for PostgreSQL, the <code>DjangoAnnotationVectorStore</code> enables efficient vector search operations within the Django application. This allows for fast and accurate retrieval of relevant annotations based on their vector embeddings, improving the overall performance of the application.</li> <li>Compatibility with LlamaIndex: The <code>DjangoAnnotationVectorStore</code> is designed to be compatible with LlamaIndex's query engines and retrieval methods. This compatibility allows the Django application to benefit from the powerful natural language processing capabilities provided by LlamaIndex, such as semantic search, question answering, and document summarization.</li> <li>Customization and Extensibility: The <code>DjangoAnnotationVectorStore</code> provides a flexible and extensible foundation for building custom vector search functionality within a Django application. It can be easily adapted and extended to meet specific application requirements, such as adding new filtering options or incorporating additional metadata fields.</li> </ol>"},{"location":"extract_and_retrieval/intro_to_django_annotation_vector_store/#conclusion","title":"Conclusion","text":"<p>By implementing the <code>DjangoAnnotationVectorStore</code> and integrating it with LlamaIndex, a Django application can achieve powerful vector search capabilities within its structured annotation store. The custom vector store leverages Django's ORM and the <code>pg-vector</code> extension for PostgreSQL to enable efficient retrieval of granular annotations based on vector similarity.</p> <p>This integration opens up new possibilities for building intelligent and interactive applications that can process and analyze large volumes of annotated data. With the combination of Django's robust web framework and LlamaIndex's advanced natural language processing capabilities, developers can create sophisticated applications that deliver enhanced user experiences and insights.</p> <p>The <code>DjangoAnnotationVectorStore</code> serves as a bridge between the Django ecosystem and the powerful tools provided by LlamaIndex, enabling developers to harness the best of both worlds in their applications.</p>"},{"location":"extract_and_retrieval/querying_corpus/","title":"Answering Queries using LlamaIndex in a Django Application","text":"<p>This markdown document explains how queries are answered in a Django application using LlamaIndex, the limitations of the approach, and how LlamaIndex is leveraged for this purpose.</p>"},{"location":"extract_and_retrieval/querying_corpus/#query-answering-process","title":"Query Answering Process","text":"<ol> <li>A user submits a query through the Django application, which is associated with a specific corpus (a collection of documents).</li> <li>The query is saved in the database as a <code>CorpusQuery</code> object, and a Celery task (<code>run_query</code>) is triggered to process the query asynchronously.</li> <li>Inside the <code>run_query</code> task:</li> <li>The <code>CorpusQuery</code> object is retrieved from the database using the provided <code>query_id</code>.</li> <li>The query's <code>started</code> timestamp is set to the current time.</li> <li>The necessary components for query processing are set up, including the embedding model (<code>HuggingFaceEmbedding</code>), language model (<code>OpenAI</code>), and vector store (<code>DjangoAnnotationVectorStore</code>).</li> <li>The <code>DjangoAnnotationVectorStore</code> is initialized with the <code>corpus_id</code> associated with the query, allowing it to retrieve the relevant annotations for the specified corpus.</li> <li>A <code>VectorStoreIndex</code> is created from the <code>DjangoAnnotationVectorStore</code>, which serves as the index for the query engine.</li> <li>A <code>CitationQueryEngine</code> is instantiated with the index, specifying the number of top similar results to retrieve (<code>similarity_top_k</code>) and the granularity of the citation sources (<code>citation_chunk_size</code>).</li> <li>The query is passed to the <code>CitationQueryEngine</code>, which processes the query and generates a response.</li> <li>The response includes the answer to the query along with the source annotations used to generate the answer.</li> <li>The source annotations are parsed and converted into a markdown format, with each citation linked to the corresponding annotation ID.</li> <li>The query's <code>sources</code> field is updated with the annotation IDs used in the response.</li> <li>The query's <code>response</code> field is set to the generated markdown text.</li> <li>The query's <code>completed</code> timestamp is set to the current time.</li> <li>If an exception occurs during the query processing, the query's <code>failed</code> timestamp is set, and the stack trace is stored in the <code>stacktrace</code> field.</li> </ol>"},{"location":"extract_and_retrieval/querying_corpus/#leveraging-llamaindex","title":"Leveraging LlamaIndex","text":"<p>LlamaIndex is leveraged in the following ways to enable query answering in the Django application:</p> <ol> <li>Vector Store: LlamaIndex provides the <code>BasePydanticVectorStore</code> class, which serves as the foundation for the custom <code>DjangoAnnotationVectorStore</code>. The <code>DjangoAnnotationVectorStore</code> integrates with Django's ORM to store and retrieve annotations efficiently, allowing seamless integration with the existing Django application.</li> <li>Indexing: LlamaIndex's <code>VectorStoreIndex</code> is used to create an index from the <code>DjangoAnnotationVectorStore</code>. The index facilitates fast and efficient retrieval of relevant annotations based on the query.</li> <li>Query Engine: LlamaIndex's <code>CitationQueryEngine</code> is employed to process the queries and generate responses. The query engine leverages the index to find the most relevant annotations and uses the language model to generate a coherent answer.</li> <li>Embedding and Language Models: LlamaIndex provides abstractions for integrating various embedding and language models. In this implementation, the <code>HuggingFaceEmbedding</code> and <code>OpenAI</code> models are used, but LlamaIndex allows flexibility in choosing different models based on requirements.</li> </ol> <p>By leveraging LlamaIndex, the Django application benefits from a structured and efficient approach to query answering. LlamaIndex provides the necessary components and abstractions to handle vector storage, indexing, and query processing, allowing the application to focus on integrating these capabilities into its existing architecture.</p>"},{"location":"walkthrough/key-concepts/","title":"Key-Concepts","text":""},{"location":"walkthrough/key-concepts/#data-types","title":"Data Types","text":"<p>Text annotation data is divided into several concepts:</p> <ol> <li>Corpuses (or collections of documents). One document can be in multiple corpuses.</li> <li>Documents. Currently, these are PDFs ONLY.</li> <li>Annotations. These are either document-level annotations (the document type), text-level annotations (highlighted    text), or relationships (which apply a label between two annotations). Relationships are currently not    well-supported and may be buggy.</li> <li>Analyses. These groups of read-only annotations added by a Gremlin analyzer (see more on that below).</li> </ol>"},{"location":"walkthrough/key-concepts/#permissioning","title":"Permissioning","text":"<p>OpenContracts is built on top of the powerful permissioning framework for Django called <code>django-guardian</code>. Each GraphQL request can add a field to annotate the object-level permissions the current user has for a given object, and the frontend relies on this to determine whether to make some objects and pages read-only and whether certain features should be exposed to a given user. The capability of sharing objects with specific users is built in, but is not enabled from the frontend at the moment. Allowing such widespread sharing and user lookups could be a security hole and could also unduly tax the system. We'd like to test these capabilities more fully before letting users used them.</p>"},{"location":"walkthrough/key-concepts/#graphql","title":"GraphQL","text":""},{"location":"walkthrough/key-concepts/#mutations-and-queries","title":"Mutations and Queries","text":"<p>OpenContracts uses Graphene and GraphQL to serve data to its frontend. You can access the Graphiql playground by going to your OpenContracts root url <code>/graphql</code> - e.g. <code>https://opencontracts.opensource.legal/graphql</code>. Anonymous users have access to any public data. To authenticate and access your own data, you either need to use the login mutation to create a JWT token or login to the admin dashboard to get a Django session and auth cookie that will automatically authenticate your requests to the GraphQL endpoint.</p> <p>If you're not familiar with GraphQL, it's a very powerful way to expose your backend to the user and/or frontend clients to permit the construction of specific queries with specific data shapes. As an example, here's a request to get public corpuses and the annotated text and labels in them:</p> <p></p> <p>Graphiql comes with a built-in documentation browser. Just click \"Docs\" in the top-right of the screen to start browsing. Typically, mutations change things on the server. Queries merely request copies of data from the server. We've tried to make our schema fairly self-explanatory, but we do plan to add more descriptions and guidance to our API docs.</p>"},{"location":"walkthrough/key-concepts/#graphql-only-features","title":"GraphQL-only features","text":"<p>Some of our features are currently not accessible via the frontend. Sharing analyses and corpuses to the public, for example, can only be achieved via <code>makeCorpusPublic</code> and <code>makeAnalysisPublic</code> mutations, and only admins have this power at the moment. For our current release, we've done this to prevent large numbers of public corpuses being shared to cut down on server usage. We'd like to make a fully free and open, collaborative platform with more features to share anonymously, but this will require additional effort and compute power.</p>"},{"location":"walkthrough/step-1-add-documents/","title":"Step 1 - Add Documents","text":"<p>In order to do anything, you need to add some documents to Gremlin.</p>"},{"location":"walkthrough/step-1-add-documents/#go-to-the-documents-tab","title":"Go to the Documents tab","text":"<p>Click on the \"Documents\" entry in the menu to bring up a view of all documents you have read and/or write access to:</p> <p></p>"},{"location":"walkthrough/step-1-add-documents/#open-the-action-menu","title":"Open the Action Menu","text":"<p>Now, click on the \"Action\" dropdown to open the Action menu for available actions and click \"Import\":</p> <p></p> <p>This will bring up a dialog to load documents:</p> <p></p>"},{"location":"walkthrough/step-1-add-documents/#select-documents-to-upload","title":"Select Documents to Upload","text":"<p>Open Contracts works with PDFs only (as this helps us have a single file type with predictable data structures, formats, etc.). In the future, we'll add functionality to convert other files to PDF, but, for now, please use PDFs. It doesn't matter if they are OCRed or not as OpenContracts performs its own OCR on every PDF anyway to ensure consistent OCR quality and outputs. Once you've added documents for upload, you'll see a list of documents:</p> <p></p> <p>Click on a document to change the description or title:</p> <p></p>"},{"location":"walkthrough/step-1-add-documents/#upload-your-documents","title":"Upload Your Documents","text":"<p>Click upload to upload the documents to OpenContracts. Note Once the documents are uploaded, they are automatically processed with Tesseract amd PAWLs to create a layer of tokens - each one representing a word / symbol in the PDF an its X,Y coordinates on the page. This is what powers OpenContracts annotator and allows us to create both layout-aware and text-only annotations. While the PAWLs processing script is running, the document you uploaded will not be available for viewing and cannot be added to a corpus. You'll see a loading bar on the document until the pre-processing is complete. This is only one once and can take a long time (a couple of minutes to a max of 10) depending on the document length, quality, etc.</p> <p></p>"},{"location":"walkthrough/step-2-create-labelset/","title":"Step 2 - Create Labelset","text":""},{"location":"walkthrough/step-2-create-labelset/#why-labelsets","title":"Why Labelsets?","text":"<p>Before you can add labels, you need to decide what you want to label. A labelset should reflect the taxonomy or concepts you want to associate with text in your document. This can be solely for the purpose of human review and retrieval, but we imagine many of you want to use it to train machine learning models.</p> <p>At the moment, there's no way to create a label in a corpus without creating a labelset and creating a label for the labelset (though we'd like to add that and welcome contributions).</p>"},{"location":"walkthrough/step-2-create-labelset/#create-text-labels","title":"Create Text Labels","text":"<p>Let's say we want to add some labels for \"Parties\", \"Termination Clause\", and \"Effective Date\". To do that, let's first create a LabelSet to hold the labels.</p> <ol> <li>Go to the labelset view and click the action button to bring up the action menu:    </li> <li>Clicking on the \"Create Label Set\" item will bring up a modal to let you create labels:    </li> <li>Now click on the new label set to edit the labels:    </li> <li> <p>A modal comes up that lets you edit three types of labels:</p> <ol> <li>Text Labels - are meant to label spans of text (\"highlights\")</li> <li>Relationship Labels - this feature is still under development, but it labels relationships bewteen text label     (e.g. one labelled party is the \"Parent Company\" of another).</li> <li>Doc Type Labels - are meant to label what category the document belongs in - e.g. a \"Stock Purchase Agreement\"      or an \"NDA\"</li> </ol> </li> <li> <p>Click the \"Text Labels\" tab to bring up a view of current labels for text annotations and an action    button that lets you create new ones. There should be no labels when you first open this view\"    </p> </li> <li>Click the action button and then the \"Create Text Label\" dropdown item:    </li> <li>You'll see a new, blank label in the list of text labels:    </li> <li>Click the edit icon on the label to edit the label title, description, color    and/or icon. To edit the icon or highlight color, hover over or click the giant    tag icon on the left side of the label:    </li> <li>Hit save to commit the changes to the database. Repeat for the other labels - \"Parties\",    \"Termination Clause\", and \"Effective Date\":    </li> </ol>"},{"location":"walkthrough/step-2-create-labelset/#create-document-type-labels","title":"Create Document-Type Labels","text":"<p>In addition to labelling specific parts of a document, you may want to tag a document itself as a certain type of document or addressing a certain subject. In this example, let's say we want to label some documents as \"contracts\" and others as \"not contracts\".</p> <ol> <li>Let's also create two example document type labels. Click the \"Doc Type Labels\" tab:    </li> <li>As before, click the action button and the \"Create Document Type Label\" item to create a    blank document type label:    </li> <li>Repeat to create two doc type labels - \"Contract\" and \"Not Contract\":    </li> <li>Hit \"Close\" to close the editor.</li> </ol>"},{"location":"walkthrough/step-3-create-a-corpus/","title":"Step 3 - Create Corpus","text":""},{"location":"walkthrough/step-3-create-a-corpus/#purpose-of-the-corpus","title":"Purpose of the Corpus","text":"<p>A \"Corpus\" is a collection of documents that can be annotated by hand or automatically by a \"Gremlin\" analyzer. In order to create a Corpus, you first need to create a Corpus and then add documents to it.</p>"},{"location":"walkthrough/step-3-create-a-corpus/#go-to-the-corpus-page","title":"Go to the Corpus Page","text":"<ol> <li>First, login if you're not already logged in.</li> <li>Then, go the \"Corpus\" tab and click the \"Action\" dropdown to bring up    the action menu:    </li> <li>Click \"Create Corpus\" to bring up the Create Corpus dialog. If you've already created a labelset or have a    pre-existing one, you can select it, otherwise you'll need to create and add one later:    </li> <li>Assuming you created the labelset you want to use, when you click on the dropdown in the \"Label Set\" section, you    should see your new labelset. Click on it to select it:    </li> <li>You will now be able to open the corpus again, open documents in the corpus and start labelling.</li> </ol>"},{"location":"walkthrough/step-3-create-a-corpus/#add-documents-to-corpus","title":"Add Documents to Corpus","text":"<ol> <li>Once you have a corpus, go back to the document page to select documents to add. You can do this in one of two ways.<ol> <li>Right-click on a document to show a context menu:       </li> <li>Or, SHIFT + click on the documents you want to select in order to select multiple documents at once. A green       checkmark will appear on selected documents.       </li> </ol> </li> <li>When you're done, click the \"Action\"    </li> <li>A dialog will pop up asking you to select a corpus to add the documents to. Select the desired corpus and    hit ok.    </li> <li>You'll get a confirmation dialog. Hit OK.</li> <li>When you click on the Corpus you just added the documents to, you'll get a tabbed view of all of the    documents, annotations and analyses for that Corpus. At this stage, you should see your documents:    </li> </ol> <p>Congrats! You've created a corpus to hold annotations or perform an analysis! In order to start labelling it yourself, you need to create and then select a LabelSet, however. You do not need to do this to run an analyzer, however.</p> <p>Note: If you have an OpenContracts export file and proper permissions, you can also import a corpus, documents, annotations, and labels. This is disabled on our demo instance, however, to but down on server load and reduce opportunities to upload potentially malicious files. See the \"Advanced\" section for more details.</p>"},{"location":"walkthrough/step-4-create-text-annotations/","title":"Step 4 - Create Some Annotations","text":"<p>To view or edit annotations, you need to open a corpus and then open a document in the Corpus.</p> <ol> <li>Go to your Corpuses page and click on the corpus you just created:</li> <li>This will open up the document view again. Click on one of the documents to bring up the annotator:    </li> <li>To select the label to apply, Click the vertical ellipses in the \"Text Label to Apply Widget\". This    will bring up an interface that lets you search your labelset and select a label:    </li> <li>Select the \"Effective Date\" label, for example, to label the Effective Date:    </li> <li>Now, in the document, click and drag a box around the language that corresponds to    your select label:    </li> <li>When you've selected the correct text, release the mouse. You'll see a confirmtion when your annotation    is created (you'll also see the annotation in the sidebar to the left):    </li> <li>If you want to delete the annotation, you can click on the trash icon in the corresponding annotation card in the    sidebar, or, when you hover over the annotation on the page, you'll see a trash icon in the label bar of the    annotation. You can click this to delete the annotation too.    </li> <li>If your desired annotated text is non-contiguous, you can hold down the SHIFT key while selecting blocks of text    to combine them into a single annotation. While holding SHIFT, releasing the mouse will not create the annotation in    the database, it will just allow you to move to a new area.<ol> <li>One situation you might want to do this is where what you want to highlight is on different lines but is just a       small part of the surrounding paragraph (such as this example, where Effective Date spans two lines):       </li> <li>Or you might want to select multiple snippets of text in a larger block of text, such as where you have multiple       parties you want to combine into a single annotation:       </li> </ol> </li> </ol>"},{"location":"walkthrough/step-5-create-doc-type-annotations/","title":"Step 5 - Create Some Document Annotations","text":"<ol> <li>If you want to label the type of document instead of the text inside it, use the controls in the \"Doc Type\"    widget on the bottom right of the Annotator. Hover over it and a green plus button should appear:    </li> <li>Click the \"+\" button to bring up a dialog that lets you search and select document type labels (remember, we created    these earlier in the tutorial):    </li> <li>Click \"Add Label\" to actually apply the label, and you'll now see that label displayed in the \"Doc Type\"    widget in the annotator:    </li> <li>As before, you can click the trash can to delete the label.</li> </ol>"},{"location":"walkthrough/step-6-search-and-filter-by-annotations/","title":"Step 6 - Search and Filter By Annotations","text":"<ol> <li>Back in the Corpus view, you can see in the document view the document type label you just added:    </li> <li>You can click on the filter dropdown above to filter the documents to only those with a certain doc type label:    </li> <li>With the corpus opened, click on the \"Annotations\" tab instead of the \"Documents\" tab to get a summary    of all the current annotations in the Corpus:    </li> <li>Click on an annotation card to automatically load the document it's in and jump right to the page containing the    annotation:    </li> </ol>"},{"location":"walkthrough/step-7-query-corpus/","title":"Querying a Corpus","text":"<p>Once you've created a corpus of documents, you can ask a natural language question and get a natural language answer, complete with citation and links back to the relevant text in the document(s)</p> <p></p> <p>Note: We're still working to improve nav and GUI performance, but this is pretty good for a first cut.</p>"},{"location":"walkthrough/step-8-data-extract/","title":"Build a Datagrid","text":"<p>You can easily use OpenContracts to create an \"Extract\" - a collection of queries and natural language-specified data points, represented as columns in a grid, that will be asked of every document in the extract (represented as rows). You can define complex extract schemas, including python primitives, Pydantic models (no nesting - yet) and lists.</p>"},{"location":"walkthrough/step-8-data-extract/#building-a-datagrid","title":"Building a Datagrid","text":"<p>To create a data grid, you can start by adding documents or adding data fields. Your choice. If you selected a corpus when defining the extract, the documents from that Corpus will be pre-loaded.</p>"},{"location":"walkthrough/step-8-data-extract/#to-add-documents","title":"To add documents:","text":""},{"location":"walkthrough/step-8-data-extract/#and-to-add-data-fields","title":"And to add data fields:","text":""},{"location":"walkthrough/step-8-data-extract/#running-an-extract","title":"Running an Extract","text":"<p>Once you've added all of the documents you want and defined all of the data fields to apply, you can click run to start processing the grid:</p> <p></p> <p>Extract speed will depend on your underlying LLM and the number of available celery workers provisioned for OpenContracts. We hope to do more performance optimization in a v2 minor release. We haven't optimized for performance at all.</p>"},{"location":"walkthrough/step-8-data-extract/#reviewing-results","title":"Reviewing Results","text":"<p>Once an extract is complete, you can click on the hamburger menu in a cell to see a dropdown menu. Click the eye to view the sources for that datacell. If you click thumbs up or thumbs down, you can log that you approved or rejected the value in question. Extract value edits are coming soon.</p> <p>See a quick walkthrough here:</p> <p></p>"},{"location":"walkthrough/advanced/configure-annotation-view/","title":"Configure How Annotations Are Displayed","text":"<p>Annotations are composed of tokens (basically text in a line surrounded by whitespace). The tokens have a highlight. OpenContracts also has a \"BoundingBox\" around the tokens which is the smallest rectangle that can cover all of the tokens in an Annotation.</p> <p>In the Annotator view, you'll see a purple-colored \"eye\" icon in the top left of the annotation list in the sidebar. Click the icon to bring up a series of configurations for how annotations are displayed:</p> <p></p> <p>There are three different settings that can be combined to significantly change how you see the annotations: 1. Show only selected - You will only see the annotation selected, either by clicking on it in the sidebar or when you    clicked into an annotation from the Corpus view. All other annotations will be completely hidden. 2. Show bounding boxes - If you unselect this, only the tokens will be visible. This is recommended where you large    numbers of overlapping annotations or annotations that are sparse - e.g. a few words scattered throughout a paragraph.    In either of these cases, the bounding boxes can cover other bounding boxes and this can be confusing. Where you have    too many overlapping bounding boxes, it's easier to hide them and just look at the tokens. 3. Label Display Behavior - has three options:</p> <ol> <li>Always Show - Always show the label for an annotation when it's displayed (remember, you can choose to only           display selected annotations).</li> <li>Always Hide - Never show the label for an annotation, regardless of its visiblity.</li> <li>Show on Hover - If an annotation is visible, when you hover over it, you'll see the label.</li> </ol>"},{"location":"walkthrough/advanced/export-import-corpuses/","title":"Export / Import Functionality","text":""},{"location":"walkthrough/advanced/export-import-corpuses/#exports","title":"Exports","text":"<p>OpenContracts support both exporting and importing corpuses. This functionality is disabled on the public demo as it can be bandwidth intensive. If you want to experiment with these features on your own, you'll see the export action when you right-click on a corpus:</p> <p></p> <p>You can access your exports from the user dropdown menu in the top right corner of the screen. Once your export is complete, you should be able to download a zip containing all the documents, their PAWLs layers, and the corpus data you created - including all annotations.</p>"},{"location":"walkthrough/advanced/export-import-corpuses/#imports","title":"Imports","text":"<p>If you've enabled corpus imports (see the frontend env file for the boolean toggle to do this - it's <code>REACT_APP_ALLOW_IMPORTS</code>), you'll see an import action when you click the action button on the corpus page.</p>"},{"location":"walkthrough/advanced/export-import-corpuses/#export-format","title":"Export Format","text":""},{"location":"walkthrough/advanced/export-import-corpuses/#opencontracts-export-format-specification","title":"OpenContracts Export Format Specification","text":"<p>The OpenContracts export is a zip archive containing: 1. A <code>data.json</code> file with metadata about the export 2. The original PDF documents 3. Exported annotations \"burned in\" to the PDF documents</p>"},{"location":"walkthrough/advanced/export-import-corpuses/#datajson-format","title":"data.json Format","text":"<p>The <code>data.json</code> file contains a JSON object with the following fields:</p> <ul> <li> <p><code>annotated_docs</code> (dict): Maps PDF filenames to OpenContractDocExport objects with annotations for that document.</p> </li> <li> <p><code>doc_labels</code> (dict): Maps document label names (strings) to AnnotationLabelPythonType objects defining those labels.</p> </li> <li> <p><code>text_labels</code> (dict): Maps text annotation label names (strings) to AnnotationLabelPythonType objects defining those labels.</p> </li> <li> <p><code>corpus</code> (OpenContractCorpusType): Metadata about the exported corpus, with fields:</p> <ul> <li><code>id</code> (int): ID of the corpus</li> <li><code>title</code> (string)</li> <li><code>description</code> (string)</li> <li><code>icon_name</code> (string): Filename of the corpus icon image</li> <li><code>icon_data</code> (string): Base64 encoded icon image data</li> <li><code>creator</code> (string): Email of the corpus creator</li> <li><code>label_set</code> (string): ID of the labelset used by this corpus</li> </ul> </li> <li> <p><code>label_set</code> (OpenContractsLabelSetType): Metadata about the label set, with fields:</p> <ul> <li><code>id</code> (int)</li> <li><code>title</code> (string)</li> <li><code>description</code> (string)</li> <li><code>icon_name</code> (string): Filename of the labelset icon</li> <li><code>icon_data</code> (string): Base64 encoded labelset icon data</li> <li><code>creator</code> (string): Email of the labelset creator</li> </ul> </li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#opencontractdocexport-format","title":"OpenContractDocExport Format","text":"<p>Each document in <code>annotated_docs</code> is represented by an OpenContractDocExport object with fields:</p> <ul> <li><code>doc_labels</code> (list[string]): List of document label names applied to this doc</li> <li><code>labelled_text</code> (list[OpenContractsAnnotationPythonType]): List of text annotations</li> <li><code>title</code> (string): Document title</li> <li><code>content</code> (string): Full text content of the document</li> <li><code>description</code> (string): Description of the document</li> <li><code>pawls_file_content</code> (list[PawlsPagePythonType]): PAWLS parse data for each page</li> <li><code>page_count</code> (int): Number of pages in the document</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#opencontractsannotationpythontype-format","title":"OpenContractsAnnotationPythonType Format","text":"<p>Represents an individual text annotation, with fields:</p> <ul> <li><code>id</code> (string): Optional ID</li> <li><code>annotationLabel</code> (string): Name of the label for this annotation</li> <li><code>rawText</code> (string): Raw text content of the annotation</li> <li><code>page</code> (int): 0-based page number the annotation is on</li> <li><code>annotation_json</code> (dict): Maps page numbers to OpenContractsSinglePageAnnotationType</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#opencontractssinglepageannotationtype-format","title":"OpenContractsSinglePageAnnotationType Format","text":"<p>Represents the annotation data for a single page:</p> <ul> <li><code>bounds</code> (BoundingBoxPythonType): Bounding box of the annotation on the page</li> <li><code>tokensJsons</code> (list[TokenIdPythonType]): List of PAWLS tokens covered by the annotation</li> <li><code>rawText</code> (string): Raw text of the annotation on this page</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#boundingboxpythontype-format","title":"BoundingBoxPythonType Format","text":"<p>Represents a bounding box with fields:</p> <ul> <li><code>top</code> (int)</li> <li><code>bottom</code> (int)</li> <li><code>left</code> (int)</li> <li><code>right</code> (int)</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#tokenidpythontype-format","title":"TokenIdPythonType Format","text":"<p>References a PAWLS token by page and token index:</p> <ul> <li><code>pageIndex</code> (int)</li> <li><code>tokenIndex</code> (int)</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#pawlspagepythontype-format","title":"PawlsPagePythonType Format","text":"<p>Represents PAWLS parse data for a single page:</p> <ul> <li><code>page</code> (PawlsPageBoundaryPythonType): Page boundary info</li> <li><code>tokens</code> (list[PawlsTokenPythonType]): List of PAWLS tokens on the page</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#pawlspageboundarypythontype-format","title":"PawlsPageBoundaryPythonType Format","text":"<p>Represents the page boundary with fields:</p> <ul> <li><code>width</code> (float)</li> <li><code>height</code> (float)</li> <li><code>index</code> (int): Page index</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#pawlstokenpythontype-format","title":"PawlsTokenPythonType Format","text":"<p>Represents a single PAWLS token with fields:</p> <ul> <li><code>x</code> (float): X-coordinate of token box</li> <li><code>y</code> (float): Y-coordinate of token box</li> <li><code>width</code> (float): Width of token box</li> <li><code>height</code> (float): Height of token box</li> <li><code>text</code> (string): Text content of the token</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#annotationlabelpythontype-format","title":"AnnotationLabelPythonType Format","text":"<p>Defines an annotation label with fields:</p> <ul> <li><code>id</code> (string)</li> <li><code>color</code> (string): Hex color for the label</li> <li><code>description</code> (string)</li> <li><code>icon</code> (string): Icon name</li> <li><code>text</code> (string): Label text</li> <li><code>label_type</code> (LabelType): One of DOC_TYPE_LABEL, TOKEN_LABEL, RELATIONSHIP_LABEL, METADATA_LABEL</li> </ul>"},{"location":"walkthrough/advanced/export-import-corpuses/#example-datajson","title":"Example data.json","text":"<pre><code>{\n  \"annotated_docs\": {\n    \"document1.pdf\": {\n      \"doc_labels\": [\"Contract\", \"NDA\"],\n      \"labelled_text\": [\n        {\n          \"id\": \"1\",\n          \"annotationLabel\": \"Effective Date\",\n          \"rawText\": \"This agreement is effective as of January 1, 2023\",\n          \"page\": 0,\n          \"annotation_json\": {\n            \"0\": {\n              \"bounds\": {\n                \"top\": 100,\n                \"bottom\": 120,\n                \"left\": 50,\n                \"right\": 500\n              },\n              \"tokensJsons\": [\n                {\n                  \"pageIndex\": 0,\n                  \"tokenIndex\": 5\n                },\n                {\n                  \"pageIndex\": 0,\n                  \"tokenIndex\": 6\n                }\n              ],\n              \"rawText\": \"January 1, 2023\"\n            }\n          }\n        }\n      ],\n      \"title\": \"Nondisclosure Agreement\",\n      \"content\": \"This Nondisclosure Agreement is made...\",\n      \"description\": \"Standard mutual NDA\",\n      \"pawls_file_content\": [\n        {\n          \"page\": {\n            \"width\": 612,\n            \"height\": 792,\n            \"index\": 0\n          },\n          \"tokens\": [\n            {\n              \"x\": 50,\n              \"y\": 100,\n              \"width\": 60,\n              \"height\": 10,\n              \"text\": \"This\"\n            },\n            {\n              \"x\": 120,\n              \"y\": 100,\n              \"width\": 100,\n              \"height\": 10,\n              \"text\": \"agreement\"\n            }\n          ]\n        }\n      ],\n      \"page_count\": 5\n    }\n  },\n  \"doc_labels\": {\n    \"Contract\": {\n      \"id\": \"1\",\n      \"color\": \"#FF0000\",\n      \"description\": \"Indicates a legal contract\",\n      \"icon\": \"contract\",\n      \"text\": \"Contract\",\n      \"label_type\": \"DOC_TYPE_LABEL\"\n    },\n    \"NDA\": {\n      \"id\": \"2\",\n      \"color\": \"#00FF00\",\n      \"description\": \"Indicates a non-disclosure agreement\",\n      \"icon\": \"nda\",\n      \"text\": \"NDA\",\n      \"label_type\": \"DOC_TYPE_LABEL\"\n    }\n  },\n  \"text_labels\": {\n    \"Effective Date\": {\n      \"id\": \"3\",\n      \"color\": \"#0000FF\",\n      \"description\": \"The effective date of the agreement\",\n      \"icon\": \"calendar\",\n      \"text\": \"Effective Date\",\n      \"label_type\": \"TOKEN_LABEL\"\n    }\n  },\n  \"corpus\": {\n    \"id\": 1,\n    \"title\": \"Example Corpus\",\n    \"description\": \"A sample corpus for demonstration\",\n    \"icon_name\": \"corpus_icon.png\",\n    \"icon_data\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAACklEQVR4nGMAAQAABQABDQottAAAAABJRU5ErkJggg==\",\n    \"creator\": \"user@example.com\",\n    \"label_set\": \"4\"\n  },\n  \"label_set\": {\n    \"id\": \"4\",\n    \"title\": \"Example Label Set\",\n    \"description\": \"A sample label set\",\n    \"icon_name\": \"label_icon.png\",\n    \"icon_data\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAACklEQVR4nGMAAQAABQABDQottAAAAABJRU5ErkJggg==\",\n    \"creator\":  \"user@example.com\"\n  }\n}\n</code></pre> <p>This <code>data.json</code> file includes:</p> <ul> <li>One annotated document (<code>document1.pdf</code>) with two document labels (\"Contract\" and \"NDA\") and one text annotation for the \"Effective Date\"</li> <li>Definitions for the two document labels (\"Contract\" and \"NDA\") and one text label (\"Effective Date\")</li> <li>Metadata about the exported corpus and labelset, including Base64 encoded icon data</li> </ul> <p>The PAWLS token data and text content are truncated for brevity. In a real export, the <code>pawls_file_content</code> would include the complete token data for each page, and <code>content</code> would contain the full extracted text of the document.</p> <p>Let me know if you have any other questions!</p>"},{"location":"walkthrough/advanced/fork-a-corpus/","title":"Fork a Corpus","text":""},{"location":"walkthrough/advanced/fork-a-corpus/#to-fork-or-not-to-fork","title":"To Fork or Not to Fork?","text":"<p>One of the amazing things about Open Source collaboration is you can stand on the shoulder of giants - we can share techniques and data and collectively achieve what we could never do alone. OpenContracts is designed to make it super easy to share and re-use annotation data.</p> <p>In OpenContracts, we introduce the concept of \"forking\" a corpus - basically creating a copy of public or private corpus, complete with its documents and annotations, which you can edit and tweak as needed. This opens up some interesting possibilities. For example, you might have a base corpus with annotations common to many types of AI models or annotation projects which you can fork as needed and layer task or domain-specific annotations on top of.</p>"},{"location":"walkthrough/advanced/fork-a-corpus/#fork-a-corpus","title":"Fork a Corpus","text":"<p>Forking a corpus is easy.</p> <ol> <li>Again, right-click on a corpus to bring up the context menu. You'll see an entry to \"Fork Corpus\":    </li> <li>Click on it to start a fork. You should see a confirmation in the top right of the screen:    </li> <li>Once the fork is complete, the next time you go to your Corpus page, you'll see a new Corpus with a Fork    icon in the icon bar at the bottom. If you hover over it, you'll be able to see a summary of the corpus it was    forked from. This is tracked in the database, so, long-term, we'd like to have corpus version control similar to how    git works:    </li> </ol>"},{"location":"walkthrough/advanced/generate-graphql-schema-files/","title":"Generate GraphQL Schema Files","text":""},{"location":"walkthrough/advanced/generate-graphql-schema-files/#generating-graphql-schema-files","title":"Generating GraphQL Schema Files","text":"<p>Open Contracts uses Graphene to provide a rich GraphQL endpoint, complete with the GraphiQL query application. For some applications, you may want to generate a GraphQL schema file in SDL or json. On example use case is if you're developing a frontend you want to connect to OpenContracts, and you'd like to autogenerate Typescript types from a GraphQL Schena.</p> <p>To generate a GraphQL schema file, run your choice of the following commands.</p> <p>For an SDL file:</p> <pre><code>$ docker-compose -f local.yml run django python manage.py graphql_schema --schema config.graphql.schema.schema --out schema.graphql\n</code></pre> <p>For a JSON file:</p> <pre><code>$ docker-compose -f local.yml run django python manage.py graphql_schema --schema config.graphql.schema.schema --out schema.json\n</code></pre> <p>You can convert these to TypeScript for use in a frontend (though you'll find this has already been done for the React- based OpenContracts frontend) using a tool like this.</p>"},{"location":"walkthrough/advanced/pawls-token-format/","title":"Understanding the PAWLs Format in OpenContracts","text":"<p>The OpenContracts project utilizes the PAWLs format for representing documents and their annotations. PAWLs is designed to provide a consistent and structured way to store text and layout information for complex documents like contracts, scientific papers, and newspapers.</p>"},{"location":"walkthrough/advanced/pawls-token-format/#pawls-layers","title":"PAWLs Layers","text":"<p>In OpenContracts, every document is processed through a pipeline that extracts and structures text and layout information into three files:</p> <ol> <li>Original PDF: The original PDF document.</li> <li>PAWLs Layer (JSON): A JSON file containing the text and positional data for each token (word) in the document.</li> <li>Text Layer: A text file containing the full text extracted from the document.</li> </ol> <p>The PAWLs layer serves as the source of truth for the document, allowing seamless translation between text and positional information.</p>"},{"location":"walkthrough/advanced/pawls-token-format/#pawls-processing-pipeline","title":"PAWLs Processing Pipeline","text":"<p>The PAWLs processing pipeline involves the following steps:</p> <ol> <li>OCR: The original PDF is re-OCRed using the open-source Tesseract OCR engine to produce a consistent output.</li> <li>Token Extraction: The OCRed document is processed using the parsing engine of Grobid to extract \"tokens\" (text surrounded by whitespace, typically a word) along with their page and positional information.</li> <li>PAWLs Layer Generation: The extracted tokens and their positional data are stored as a JSON file, referred to as the \"PAWLs layer.\"</li> <li>Text Layer Generation: The full text is extracted from the PAWLs layer and stored as a separate text file, called the \"text layer.\"</li> </ol>"},{"location":"walkthrough/advanced/pawls-token-format/#pawls-layer-structure","title":"PAWLs Layer Structure","text":"<p>The PAWLs layer JSON file consists of a list of page objects, each containing the necessary tokens and page information for a given page. Here's the data shape for each page object:</p> <pre><code>class PawlsPagePythonType(TypedDict):\n    page: PawlsPageBoundaryPythonType\n    tokens: list[PawlsTokenPythonType]\n</code></pre> <p>The <code>PawlsPageBoundaryPythonType</code> represents the page boundary information:</p> <pre><code>class PawlsPageBoundaryPythonType(TypedDict):\n    width: float\n    height: float\n    index: int\n</code></pre> <p>Each token in the <code>tokens</code> list is represented by the <code>PawlsTokenPythonType</code>:</p> <pre><code>class PawlsTokenPythonType(TypedDict):\n    x: float\n    y: float\n    width: float\n    height: float\n    text: str\n</code></pre> <p>The <code>x</code>, <code>y</code>, <code>width</code>, and <code>height</code> fields provide the positional information for each token on the page.</p>"},{"location":"walkthrough/advanced/pawls-token-format/#annotation-process","title":"Annotation Process","text":"<p>OpenContracts allows users to annotate documents using the PAWLs layer. Annotations are stored as a dictionary mapping page numbers to annotation data:</p> <pre><code>Dict[int, OpenContractsSinglePageAnnotationType]\n</code></pre> <p>The <code>OpenContractsSinglePageAnnotationType</code> represents the annotation data for a single page:</p> <pre><code>class OpenContractsSinglePageAnnotationType(TypedDict):\n    bounds: BoundingBoxPythonType\n    tokensJsons: list[TokenIdPythonType]\n    rawText: str\n</code></pre> <p>The <code>bounds</code> field represents the bounding box of the annotation, while <code>tokensJsons</code> contains a list of token IDs that make up the annotation. The <code>rawText</code> field stores the raw text of the annotation.</p>"},{"location":"walkthrough/advanced/pawls-token-format/#advantages-of-pawls","title":"Advantages of PAWLs","text":"<p>The PAWLs format offers several advantages for document annotation and NLP tasks:</p> <ol> <li>Consistent Structure: PAWLs provides a consistent and structured representation of documents, regardless of the original file format or structure.</li> <li>Layout Awareness: By storing positional information for each token, PAWLs enables layout-aware text analysis and annotation.</li> <li>Seamless Integration: The PAWLs layer allows easy integration with various NLP libraries and tools, whether they are layout-aware or not.</li> <li>Reproducibility: The re-OCR process ensures consistent output across different documents and software versions.</li> </ol>"},{"location":"walkthrough/advanced/pawls-token-format/#conclusion","title":"Conclusion","text":"<p>The PAWLs format in OpenContracts provides a powerful and flexible way to represent and annotate complex documents. By extracting and structuring text and layout information, PAWLs enables efficient and accurate document analysis and annotation tasks. The consistent structure and layout awareness of PAWLs make it an essential component of the OpenContracts project.</p>"},{"location":"walkthrough/advanced/pawls-token-format/#example-pawls-file","title":"Example PAWLs File","text":"<p>Here's an example of what a PAWLs layer JSON file might look like:</p> <pre><code>[\n  {\n    \"page\": {\n      \"width\": 612.0,\n      \"height\": 792.0,\n      \"index\": 0\n    },\n    \"tokens\": [\n      {\n        \"x\": 72.0,\n        \"y\": 720.0,\n        \"width\": 41.0,\n        \"height\": 12.0,\n        \"text\": \"Lorem\"\n      },\n      {\n        \"x\": 113.0,\n        \"y\": 720.0,\n        \"width\": 35.0,\n        \"height\": 12.0,\n        \"text\": \"ipsum\"\n      },\n      {\n        \"x\": 148.0,\n        \"y\": 720.0,\n        \"width\": 31.0,\n        \"height\": 12.0,\n        \"text\": \"dolor\"\n      },\n      {\n        \"x\": 179.0,\n        \"y\": 720.0,\n        \"width\": 18.0,\n        \"height\": 12.0,\n        \"text\": \"sit\"\n      },\n      {\n        \"x\": 197.0,\n        \"y\": 720.0,\n        \"width\": 32.0,\n        \"height\": 12.0,\n        \"text\": \"amet,\"\n      },\n      {\n        \"x\": 72.0,\n        \"y\": 708.0,\n        \"width\": 66.0,\n        \"height\": 12.0,\n        \"text\": \"consectetur\"\n      },\n      {\n        \"x\": 138.0,\n        \"y\": 708.0,\n        \"width\": 60.0,\n        \"height\": 12.0,\n        \"text\": \"adipiscing\"\n      },\n      {\n        \"x\": 198.0,\n        \"y\": 708.0,\n        \"width\": 24.0,\n        \"height\": 12.0,\n        \"text\": \"elit.\"\n      }\n    ]\n  },\n  {\n    \"page\": {\n      \"width\": 612.0,\n      \"height\": 792.0,\n      \"index\": 1\n    },\n    \"tokens\": [\n      {\n        \"x\": 72.0,\n        \"y\": 756.0,\n        \"width\": 46.0,\n        \"height\": 12.0,\n        \"text\": \"Integer\"\n      },\n      {\n        \"x\": 118.0,\n        \"y\": 756.0,\n        \"width\": 35.0,\n        \"height\": 12.0,\n        \"text\": \"vitae\"\n      },\n      {\n        \"x\": 153.0,\n        \"y\": 756.0,\n        \"width\": 39.0,\n        \"height\": 12.0,\n        \"text\": \"augue\"\n      },\n      {\n        \"x\": 192.0,\n        \"y\": 756.0,\n        \"width\": 45.0,\n        \"height\": 12.0,\n        \"text\": \"rhoncus\"\n      },\n      {\n        \"x\": 237.0,\n        \"y\": 756.0,\n        \"width\": 57.0,\n        \"height\": 12.0,\n        \"text\": \"fermentum\"\n      },\n      {\n        \"x\": 294.0,\n        \"y\": 756.0,\n        \"width\": 13.0,\n        \"height\": 12.0,\n        \"text\": \"at\"\n      },\n      {\n        \"x\": 307.0,\n        \"y\": 756.0,\n        \"width\": 29.0,\n        \"height\": 12.0,\n        \"text\": \"quis.\"\n      }\n    ]\n  }\n]\n</code></pre> <p>In this example, the PAWLs layer JSON file contains an array of two page objects. Each page object has a <code>page</code> field with the page dimensions and index, and a <code>tokens</code> field with an array of token objects.</p> <p>Each token object represents a word or a piece of text on the page, along with its positional information. The <code>x</code> and <code>y</code> fields indicate the coordinates of the token's bounding box, while <code>width</code> and <code>height</code> specify the dimensions of the bounding box. The <code>text</code> field contains the actual text content of the token.</p> <p>The tokens are ordered based on their appearance on the page, allowing for the reconstruction of the document's text content while preserving the layout information.</p> <p>This sample demonstrates the structure and content of a PAWLs layer JSON file, which serves as the foundation for annotation and analysis tasks in the OpenContracts project.</p>"},{"location":"walkthrough/advanced/run-gremlin-analyzer/","title":"Run a Gremlin Analyzer","text":""},{"location":"walkthrough/advanced/run-gremlin-analyzer/#introduction-to-gremlin-integration","title":"Introduction to Gremlin Integration","text":"<p>OpenContracts integrates with a powerful NLP engine called Gremlin Engine (\"Gremlin\"). If you run a Gremlin analyzer on a Corpus, it will create annotations of its own that you can view and export (e.g. automatically applying document labels or labeling parties, dates, and places, etc.). It's meant to provide a consistent API to deliver and render NLP and machine learning capabilities to end-users. As discussed in the configuration section, you need to install Gremlin Analyzers through the admin dashboard.</p> <p>Once you've installed Gremlin Analyzers, however, it's easy to apply them.</p>"},{"location":"walkthrough/advanced/run-gremlin-analyzer/#using-an-installed-gremlin-analyzer","title":"Using an Installed Gremlin Analyzer","text":"<ol> <li> <p>If analysis capabilities are enabled for instance, when you right-click on a Corpus, you'll see an option to    \"Analyze Corpus\":   </p> </li> <li> <p>Clicking on this item will bring up a dialog where you can browse available analyzers:   </p> </li> <li> <p>Select one and hit \"Analyze\" to submit a corpus for processing. When you go to the Analysis tab of your    Corpus now, you'll see the analysis. Most likely, if you just clicked there, it will say processing:    </p> </li> <li> <p>When the Analysis is complete, you'll see a summary of the number of labels and annotations applied by the analyzer:    </p> </li> </ol>"},{"location":"walkthrough/advanced/run-gremlin-analyzer/#note-on-processing-time","title":"Note on Processing Time","text":"<p>Large Corpuses of hundreds of documents can take a long time to process (10 minutes or more). It's hard to predict processing time up front, because it's dependent on the number of total pages and the specific analysis being performed. At the moment, there is not a great mechanism in place to detect and handle failures in a Gremlin analyzer and reflect this in OpenContracts. It's on our roadmap to improve this integration. In the meantime, the example analyzers we've released with Gremlin should be very stable, so they should run predictably.</p>"},{"location":"walkthrough/advanced/run-gremlin-analyzer/#viewing-the-outputs","title":"Viewing the Outputs","text":"<p>Once an Analysis completes, you'll be able to browse the annotations from the analysis in several ways.</p> <ol> <li>First, they'll be available in the \"Annotation\" tab, and you can easily filter to annotations from a    specific analyzer.</li> <li>Second, when you load a Document, in the Annotator view, there's a small widget in the top of the annotator    that has three downwards-facing arrows and says \"Human Annotation Mode\".    </li> <li>Click on the arrows open a tray showing the analyses applied to this document.</li> <li>Click on an analysis to load the annotations and view them in the document.    </li> </ol> <p>Note: You can delete an analysis, but you cannot edit it. The annotations are machine-created and cannot be edited by human users.</p>"}]}